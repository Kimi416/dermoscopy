"""
2ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆé«˜é€Ÿç‰ˆï¼‰
EfficientNet + ResNet ã«ã‚ˆã‚‹ SKèª¤åˆ†é¡æ”¹å–„ãƒ†ã‚¹ãƒˆ
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torchvision.models import efficientnet_v2_s, resnet50
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, accuracy_score, classification_report, confusion_matrix
import numpy as np
from PIL import Image
import os
import glob
import json

# ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')

# ç–¾æ‚£åˆ†é¡å®šç¾©
DISEASE_MAPPING = {
    'AK': {'type': 'malignant', 'full_name': 'Actinic Keratosis'},
    'BCC': {'type': 'malignant', 'full_name': 'Basal Cell Carcinoma'}, 
    'Bowenç—…': {'type': 'malignant', 'full_name': 'Bowen Disease'},
    'MM': {'type': 'malignant', 'full_name': 'Malignant Melanoma'},
    'SK': {'type': 'benign', 'full_name': 'Seborrheic Keratosis'}
}

class DualModel(nn.Module):
    """ãƒ‡ãƒ¥ã‚¢ãƒ«ãƒ¢ãƒ‡ãƒ«ï¼ˆEfficientNet / ResNetï¼‰"""
    
    def __init__(self, model_type='efficientnet', num_classes=2, dropout_rate=0.3):
        super().__init__()
        
        if model_type == 'efficientnet':
            self.backbone = efficientnet_v2_s(weights='IMAGENET1K_V1')
            num_features = self.backbone.classifier[1].in_features
            self.backbone.classifier = nn.Sequential(
                nn.Dropout(dropout_rate),
                nn.Linear(num_features, 512),
                nn.ReLU(),
                nn.Dropout(dropout_rate),
                nn.Linear(512, num_classes)
            )
        elif model_type == 'resnet':
            self.backbone = resnet50(weights='IMAGENET1K_V1')
            num_features = self.backbone.fc.in_features
            self.backbone.fc = nn.Sequential(
                nn.Dropout(dropout_rate),
                nn.Linear(num_features, 512),
                nn.ReLU(),
                nn.Dropout(dropout_rate),
                nn.Linear(512, num_classes)
            )
    
    def forward(self, x):
        return self.backbone(x)

class OptimizedDataset(Dataset):
    """æœ€é©åŒ–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"""
    
    def __init__(self, image_paths, labels, img_size=224, is_training=True):
        self.image_paths = image_paths
        self.labels = labels
        self.img_size = img_size
        
        if is_training:
            # å¼·åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
            self.transform = transforms.Compose([
                transforms.Resize((img_size + 56, img_size + 56)),
                transforms.RandomResizedCrop(img_size, scale=(0.75, 1.0)),
                transforms.RandomHorizontalFlip(p=0.5),
                transforms.RandomRotation(degrees=15),
                transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.1),
                transforms.RandomApply([transforms.GaussianBlur(3, sigma=(0.1, 2.0))], p=0.3),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
                transforms.RandomErasing(p=0.1, scale=(0.02, 0.1))
            ])
        else:
            self.transform = transforms.Compose([
                transforms.Resize((img_size, img_size)),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        try:
            image = Image.open(self.image_paths[idx]).convert('RGB')
            image = self.transform(image)
            return image, self.labels[idx]
        except Exception as e:
            print(f"âŒ ç”»åƒã‚¨ãƒ©ãƒ¼: {self.image_paths[idx]} - {e}")
            return torch.zeros(3, self.img_size, self.img_size), self.labels[idx]

class DualEnsembleClassifier:
    """ãƒ‡ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åˆ†é¡å™¨"""
    
    def __init__(self):
        self.models = {}
        self.model_performance = {}
        self.ensemble_weights = {}
        
    def collect_data(self, base_path='/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢'):
        """ãƒ‡ãƒ¼ã‚¿åé›†"""
        print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿åé›†ä¸­...")
        
        disease_data = {}
        all_image_paths = []
        all_labels = []
        
        for disease, info in DISEASE_MAPPING.items():
            disease_dir = os.path.join(base_path, disease)
            if not os.path.exists(disease_dir):
                continue
            
            patterns = ['*.jpg', '*.JPG', '*.jpeg', '*.png']
            image_paths = []
            for pattern in patterns:
                image_paths.extend(glob.glob(os.path.join(disease_dir, pattern)))
            
            label = 1 if info['type'] == 'malignant' else 0
            disease_data[disease] = {'paths': image_paths, 'label': label, 'count': len(image_paths)}
            
            for img_path in image_paths:
                all_image_paths.append(img_path)
                all_labels.append(label)
            
            print(f"   {disease}: {len(image_paths)}æš ({'æ‚ªæ€§' if label == 1 else 'è‰¯æ€§'})")
        
        malignant_count = sum([data['count'] for disease, data in disease_data.items() 
                              if data['label'] == 1])
        benign_count = sum([data['count'] for disease, data in disease_data.items() 
                           if data['label'] == 0])
        
        print(f"\\nğŸ“ˆ ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒ:")
        print(f"   æ‚ªæ€§: {malignant_count}æš")
        print(f"   è‰¯æ€§: {benign_count}æš") 
        print(f"   åˆè¨ˆ: {len(all_image_paths)}æš")
        print(f"   ä¸å‡è¡¡æ¯”: {malignant_count/benign_count:.2f}:1")
        
        return all_image_paths, all_labels, disease_data
    
    def train_single_model(self, model_type, train_paths, train_labels, val_paths, val_labels, epochs=12):
        """å˜ä¸€ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        print(f"\\nğŸš€ {model_type.upper()} è¨“ç·´é–‹å§‹")
        print("-" * 40)
        
        # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        model = DualModel(model_type).to(device)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        train_dataset = OptimizedDataset(train_paths, train_labels, is_training=True)
        val_dataset = OptimizedDataset(val_paths, val_labels, is_training=False)
        
        train_loader = DataLoader(train_dataset, batch_size=24, shuffle=True, num_workers=2, pin_memory=True)
        val_loader = DataLoader(val_dataset, batch_size=48, shuffle=False, num_workers=2, pin_memory=True)
        
        # æå¤±é–¢æ•°ã¨ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
        unique_labels, counts = np.unique(train_labels, return_counts=True)
        class_weights = len(train_labels) / (len(unique_labels) * counts)
        class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)
        
        # Focal Lossé¢¨ã®é‡ã¿ä»˜ãCrossEntropy
        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor, label_smoothing=0.1)
        optimizer = optim.AdamW(model.parameters(), lr=2e-4, weight_decay=0.01)
        
        # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ä»˜ãã‚³ã‚µã‚¤ãƒ³ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°
        warmup_epochs = 2
        scheduler = optim.lr_scheduler.LambdaLR(
            optimizer, 
            lr_lambda=lambda epoch: min(1.0, epoch / warmup_epochs) if epoch < warmup_epochs 
                                   else 0.5 * (1 + np.cos(np.pi * (epoch - warmup_epochs) / (epochs - warmup_epochs)))
        )
        
        # è¨“ç·´ãƒ«ãƒ¼ãƒ—
        best_auc = 0
        best_model_state = None
        patience = 4
        no_improve = 0
        
        for epoch in range(epochs):
            # è¨“ç·´ãƒ•ã‚§ãƒ¼ã‚º
            model.train()
            train_loss = 0
            correct = 0
            total = 0
            
            for batch_idx, (images, labels) in enumerate(train_loader):
                images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
                
                optimizer.zero_grad()
                outputs = model(images)
                loss = criterion(outputs, labels)
                loss.backward()
                
                # Gradient clipping
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                
                optimizer.step()
                
                train_loss += loss.item()
                _, predicted = outputs.max(1)
                total += labels.size(0)
                correct += predicted.eq(labels).sum().item()
            
            scheduler.step()
            
            # æ¤œè¨¼ãƒ•ã‚§ãƒ¼ã‚º
            model.eval()
            val_probs = []
            val_true = []
            val_loss = 0
            
            with torch.no_grad():
                for images, labels in val_loader:
                    images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)
                    outputs = model(images)
                    loss = criterion(outputs, labels)
                    
                    probs = torch.softmax(outputs, dim=1)[:, 1]
                    
                    val_probs.extend(probs.cpu().numpy())
                    val_true.extend(labels.cpu().numpy())
                    val_loss += loss.item()
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
            train_acc = 100.0 * correct / total
            val_auc = roc_auc_score(val_true, val_probs)
            lr = scheduler.get_last_lr()[0]
            
            print(f"   Epoch {epoch+1:2d}: Loss {train_loss/len(train_loader):.4f} | "
                  f"Acc {train_acc:5.1f}% | Val AUC {val_auc:.4f} | LR {lr:.2e}")
            
            # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ä¿å­˜
            if val_auc > best_auc:
                best_auc = val_auc
                best_model_state = model.state_dict().copy()
                no_improve = 0
            else:
                no_improve += 1
                if no_improve >= patience:
                    print(f"   ğŸ›‘ æ—©æœŸåœæ­¢ (Best AUC: {best_auc:.4f})")
                    break
        
        # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«å¾©å…ƒ
        model.load_state_dict(best_model_state)
        
        # æœ€çµ‚è©•ä¾¡
        model.eval()
        final_probs = []
        final_true = []
        
        with torch.no_grad():
            for images, labels in val_loader:
                images = images.to(device)
                outputs = model(images)
                probs = torch.softmax(outputs, dim=1)[:, 1]
                
                final_probs.extend(probs.cpu().numpy())
                final_true.extend(labels.numpy())
        
        final_auc = roc_auc_score(final_true, final_probs)
        final_acc = accuracy_score(final_true, (np.array(final_probs) > 0.5).astype(int))
        
        print(f"âœ… {model_type.upper()} å®Œäº†:")
        print(f"   æœ€çµ‚AUC: {final_auc:.4f}")
        print(f"   æœ€çµ‚ç²¾åº¦: {final_acc:.4f}")
        
        return model, final_auc, final_probs, final_true
    
    def train_ensemble(self, image_paths, labels):
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨“ç·´"""
        print("ğŸ¯ ãƒ‡ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’")
        print("=" * 50)
        
        # å±¤åŒ–åˆ†å‰²
        train_paths, val_paths, train_labels, val_labels = train_test_split(
            image_paths, labels, test_size=0.25, stratify=labels, random_state=42
        )
        
        print(f"\\nğŸ“‚ ãƒ‡ãƒ¼ã‚¿åˆ†å‰²:")
        print(f"   è¨“ç·´: {len(train_paths)}æš")
        print(f"   æ¤œè¨¼: {len(val_paths)}æš")
        
        # å„ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        model_types = ['efficientnet', 'resnet']
        ensemble_probs = []
        
        for model_type in model_types:
            model, auc, val_probs, val_true = self.train_single_model(
                model_type, train_paths, train_labels, val_paths, val_labels
            )
            
            self.models[model_type] = model
            self.model_performance[model_type] = {
                'auc': auc,
                'val_probs': val_probs,
                'val_true': val_true
            }
            
            ensemble_probs.append(val_probs)
        
        # AUCãƒ™ãƒ¼ã‚¹ã®é‡ã¿è¨ˆç®—
        total_auc = sum([perf['auc'] for perf in self.model_performance.values()])
        for model_type, perf in self.model_performance.items():
            weight = perf['auc'] / total_auc
            self.ensemble_weights[model_type] = weight
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
        ensemble_prediction = np.zeros_like(ensemble_probs[0])
        for i, model_type in enumerate(model_types):
            ensemble_prediction += self.ensemble_weights[model_type] * np.array(ensemble_probs[i])
        
        ensemble_auc = roc_auc_score(val_true, ensemble_prediction)
        
        # çµæœè¡¨ç¤º
        print(f"\\nğŸ“Š å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«æ€§èƒ½:")
        for model_type, perf in self.model_performance.items():
            print(f"   {model_type.upper()}: AUC {perf['auc']:.4f} (é‡ã¿: {self.ensemble_weights[model_type]:.3f})")
        
        print(f"\\nğŸ¯ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ€§èƒ½:")
        print(f"   AUC: {ensemble_auc:.4f}")
        
        # æ··åŒè¡Œåˆ—
        ensemble_pred_binary = (ensemble_prediction > 0.5).astype(int)
        cm = confusion_matrix(val_true, ensemble_pred_binary)
        
        print(f"\\nğŸ“ˆ æ··åŒè¡Œåˆ—:")
        print(f"   TN: {cm[0,0]:3d} | FP: {cm[0,1]:3d}")
        print(f"   FN: {cm[1,0]:3d} | TP: {cm[1,1]:3d}")
        
        if cm[1,1] + cm[1,0] > 0:  # æ‚ªæ€§ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            sensitivity = cm[1,1] / (cm[1,1] + cm[1,0])
            print(f"   æ„Ÿåº¦: {sensitivity:.3f}")
        
        if cm[0,0] + cm[0,1] > 0:  # è‰¯æ€§ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯  
            specificity = cm[0,0] / (cm[0,0] + cm[0,1])
            print(f"   ç‰¹ç•°åº¦: {specificity:.3f}")
        
        return {
            'individual_aucs': {mt: perf['auc'] for mt, perf in self.model_performance.items()},
            'ensemble_auc': ensemble_auc,
            'weights': self.ensemble_weights,
            'validation_performance': {
                'sensitivity': sensitivity if 'sensitivity' in locals() else None,
                'specificity': specificity if 'specificity' in locals() else None
            }
        }
    
    def predict_ensemble(self, image_paths):
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬"""
        ensemble_probs = np.zeros(len(image_paths))
        
        for model_type, model in self.models.items():
            dataset = OptimizedDataset(image_paths, [0] * len(image_paths), is_training=False)
            loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=2)
            
            model.eval()
            probs = []
            
            with torch.no_grad():
                for images, _ in loader:
                    images = images.to(device)
                    outputs = model(images)
                    batch_probs = torch.softmax(outputs, dim=1)[:, 1]
                    probs.extend(batch_probs.cpu().numpy())
            
            ensemble_probs += self.ensemble_weights[model_type] * np.array(probs)
        
        return ensemble_probs
    
    def test_sk_classification(self, image_path='/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢/images.jpeg'):
        """SKåˆ†é¡ãƒ†ã‚¹ãƒˆ"""
        print(f"\\nğŸ§ª SKåˆ†é¡æ”¹å–„ãƒ†ã‚¹ãƒˆ")
        print("=" * 50)
        
        if not os.path.exists(image_path):
            print(f"âŒ ãƒ†ã‚¹ãƒˆç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_path}")
            return None
        
        print(f"ğŸ“‚ ãƒ†ã‚¹ãƒˆå¯¾è±¡: {os.path.basename(image_path)}")
        print("ğŸ” ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬å®Ÿè¡Œä¸­...")
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
        ensemble_prob = self.predict_ensemble([image_path])[0]
        
        # å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬
        individual_probs = {}
        for model_type, model in self.models.items():
            dataset = OptimizedDataset([image_path], [0], is_training=False)
            loader = DataLoader(dataset, batch_size=1, shuffle=False)
            
            model.eval()
            with torch.no_grad():
                for images, _ in loader:
                    images = images.to(device)
                    outputs = model(images)
                    prob = torch.softmax(outputs, dim=1)[0, 1].cpu().numpy()
                    individual_probs[model_type] = prob
        
        # çµæœè¡¨ç¤º
        print(f"\\nğŸ¯ äºˆæ¸¬çµæœ:")
        print(f"   ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«: {ensemble_prob:.1%} (æ‚ªæ€§)")
        print(f"   æœ€çµ‚åˆ¤å®š: {'æ‚ªæ€§' if ensemble_prob > 0.5 else 'è‰¯æ€§'}")
        
        print(f"\\nğŸ“Š å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«:")
        for model_type, prob in individual_probs.items():
            print(f"   {model_type.upper()}: {prob:.1%}")
        
        print(f"\\nâš–ï¸ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é‡ã¿:")
        for model_type, weight in self.ensemble_weights.items():
            print(f"   {model_type.upper()}: {weight:.3f}")
        
        # å¾“æ¥çµæœã¨ã®æ¯”è¼ƒ
        baseline_prob = 0.998  # å¾“æ¥ã‚·ã‚¹ãƒ†ãƒ ã®çµæœ
        improvement = abs(baseline_prob - ensemble_prob)
        
        print(f"\\nğŸ“ˆ æ”¹å–„åº¦åˆ†æ:")
        print(f"   å¾“æ¥ã‚·ã‚¹ãƒ†ãƒ : {baseline_prob:.1%} (æ‚ªæ€§)")
        print(f"   ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«: {ensemble_prob:.1%} (æ‚ªæ€§)")
        print(f"   ç¢ºä¿¡åº¦å¤‰åŒ–: {improvement:.1%}")
        
        if ensemble_prob < 0.5:
            print("âœ… ğŸ‰ SKèª¤åˆ†é¡å•é¡ŒãŒè§£æ±ºã•ã‚Œã¾ã—ãŸï¼")
            success = True
        else:
            print("âš ï¸ ã¾ã æ‚ªæ€§åˆ¤å®šã§ã™ãŒã€ç¢ºä¿¡åº¦ã¯ä½ä¸‹ã—ã¾ã—ãŸ")
            success = False
        
        return {
            'ensemble_probability': float(ensemble_prob),
            'individual_probabilities': {k: float(v) for k, v in individual_probs.items()},
            'prediction': 'malignant' if ensemble_prob > 0.5 else 'benign',
            'baseline_probability': baseline_prob,
            'improvement': float(improvement),
            'classification_success': success
        }

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("âš¡ ãƒ‡ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ")
    print("   EfficientNet + ResNet ã«ã‚ˆã‚‹ SKèª¤åˆ†é¡æ”¹å–„")
    print("=" * 60)
    
    classifier = DualEnsembleClassifier()
    
    # ãƒ‡ãƒ¼ã‚¿åé›†
    image_paths, labels, disease_data = classifier.collect_data()
    
    if len(image_paths) == 0:
        print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨“ç·´
    training_results = classifier.train_ensemble(image_paths, labels)
    
    # SKåˆ†é¡ãƒ†ã‚¹ãƒˆ
    sk_results = classifier.test_sk_classification()
    
    # æœ€çµ‚çµæœ
    final_results = {
        'training_results': training_results,
        'sk_test_results': sk_results,
        'data_summary': {
            'total_images': len(image_paths),
            'disease_distribution': {d: data['count'] for d, data in disease_data.items()}
        }
    }
    
    with open('/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢/dual_ensemble_results.json', 'w', encoding='utf-8') as f:
        json.dump(final_results, f, indent=2, ensure_ascii=False)
    
    print(f"\\nğŸ‰ ãƒ‡ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å®Œäº†ï¼")
    if sk_results and sk_results['classification_success']:
        print("âœ… SKèª¤åˆ†é¡å•é¡ŒãŒæ”¹å–„ã•ã‚Œã¾ã—ãŸï¼")
    else:
        print("ğŸ“ˆ æ€§èƒ½å‘ä¸Šã‚’ç¢ºèªã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()