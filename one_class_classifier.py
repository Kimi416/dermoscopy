"""
ä¸€ã‚¯ãƒ©ã‚¹åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ 
æ‚ªæ€§ç”»åƒã®ã¿ã§å­¦ç¿’ã—ã€æ‚ªæ€§ã‚‰ã—ã•ã§è‰¯æ€§ãƒ»æ‚ªæ€§ã‚’åˆ¤åˆ¥
"""

import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision.models import efficientnet_v2_s
from PIL import Image
import numpy as np
import os
import glob
from sklearn.ensemble import IsolationForest
from sklearn.svm import OneClassSVM
from sklearn.preprocessing import StandardScaler
import pickle
from datetime import datetime
import json

# ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')

# ç–¾æ‚£åˆ†é¡å®šç¾©ï¼ˆæ‚ªæ€§ã®ã¿ï¼‰
MALIGNANT_DISEASES = {
    'AK': 'Actinic Keratosis',
    'BCC': 'Basal Cell Carcinoma', 
    'Bowenç—…': 'Bowen Disease',
    'MM': 'Malignant Melanoma'
}

class FeatureExtractor(nn.Module):
    """ç‰¹å¾´æŠ½å‡ºå™¨ï¼ˆæ‚ªæ€§ç”»åƒå°‚ç”¨ï¼‰"""
    
    def __init__(self, pretrained=True):
        super().__init__()
        self.backbone = efficientnet_v2_s(weights='IMAGENET1K_V1' if pretrained else None)
        
        # ç‰¹å¾´æŠ½å‡ºç”¨ï¼ˆåˆ†é¡å±¤ã‚’é™¤å»ï¼‰
        self.features = nn.Sequential(*list(self.backbone.children())[:-1])
        self.global_pool = nn.AdaptiveAvgPool2d(1)
        
    def forward(self, x):
        features = self.features(x)
        features = self.global_pool(features)
        features = torch.flatten(features, 1)
        return features

class OneClassMalignancyDetector:
    """ä¸€ã‚¯ãƒ©ã‚¹æ‚ªæ€§æ¤œå‡ºå™¨"""
    
    def __init__(self):
        self.feature_extractor = None
        self.anomaly_detector = None
        self.scaler = StandardScaler()
        self.malignancy_threshold = 0.0
        self.training_stats = {}
        
    def extract_features_from_image(self, image_path):
        """å˜ä¸€ç”»åƒã‹ã‚‰ç‰¹å¾´æŠ½å‡º"""
        transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        try:
            image = Image.open(image_path).convert('RGB')
            image_tensor = transform(image).unsqueeze(0).to(device)
            
            with torch.no_grad():
                features = self.feature_extractor(image_tensor)
                return features.cpu().numpy().flatten()
        except Exception as e:
            print(f"âŒ ç‰¹å¾´æŠ½å‡ºã‚¨ãƒ©ãƒ¼ {image_path}: {e}")
            return None
    
    def collect_malignant_features(self, base_path='/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢'):
        """æ‚ªæ€§ç”»åƒã‹ã‚‰ç‰¹å¾´åé›†"""
        print("ğŸ” æ‚ªæ€§ç”»åƒã‹ã‚‰ç‰¹å¾´æŠ½å‡ºä¸­...")
        
        all_features = []
        image_paths = []
        disease_labels = []
        
        for disease in MALIGNANT_DISEASES.keys():
            disease_dir = os.path.join(base_path, disease)
            if not os.path.exists(disease_dir):
                print(f"âš ï¸ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {disease_dir}")
                continue
            
            # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«åé›†
            patterns = ['*.jpg', '*.JPG', '*.jpeg', '*.png']
            disease_images = []
            
            for pattern in patterns:
                disease_images.extend(glob.glob(os.path.join(disease_dir, pattern)))
            
            print(f"   {disease}: {len(disease_images)}æš")
            
            # ç‰¹å¾´æŠ½å‡º
            for img_path in disease_images:
                features = self.extract_features_from_image(img_path)
                if features is not None:
                    all_features.append(features)
                    image_paths.append(img_path)
                    disease_labels.append(disease)
        
        self.training_stats = {
            'total_images': len(all_features),
            'diseases': {disease: disease_labels.count(disease) for disease in MALIGNANT_DISEASES.keys()},
            'feature_dimension': len(all_features[0]) if all_features else 0
        }
        
        print(f"âœ… ç‰¹å¾´æŠ½å‡ºå®Œäº†: {len(all_features)}æšã®æ‚ªæ€§ç”»åƒ")
        return np.array(all_features), image_paths, disease_labels
    
    def train_anomaly_detector(self, features, method='isolation_forest'):
        """ç•°å¸¸æ¤œçŸ¥å™¨ã®è¨“ç·´"""
        print(f"ğŸ§  ç•°å¸¸æ¤œçŸ¥å™¨è¨“ç·´ä¸­... (æ‰‹æ³•: {method})")
        
        # ç‰¹å¾´é‡ã®æ­£è¦åŒ–
        features_scaled = self.scaler.fit_transform(features)
        
        if method == 'isolation_forest':
            # Isolation Forest
            self.anomaly_detector = IsolationForest(
                contamination=0.1,  # 10%ã®ç•°å¸¸ã‚’æƒ³å®š
                random_state=42,
                n_estimators=100
            )
        elif method == 'one_class_svm':
            # One-Class SVM
            self.anomaly_detector = OneClassSVM(
                kernel='rbf',
                gamma='scale',
                nu=0.1  # 10%ã®ç•°å¸¸ã‚’æƒ³å®š
            )
        else:
            raise ValueError(f"æœªå¯¾å¿œã®æ‰‹æ³•: {method}")
        
        # è¨“ç·´
        self.anomaly_detector.fit(features_scaled)
        
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½è©•ä¾¡
        train_scores = self.anomaly_detector.decision_function(features_scaled)
        self.malignancy_threshold = np.percentile(train_scores, 10)  # ä¸‹ä½10%ã‚’é–¾å€¤ã«
        
        print(f"âœ… ç•°å¸¸æ¤œçŸ¥å™¨è¨“ç·´å®Œäº†")
        print(f"   æ‚ªæ€§ã‚‰ã—ã•é–¾å€¤: {self.malignancy_threshold:.3f}")
        print(f"   è¨“ç·´ã‚¹ã‚³ã‚¢ç¯„å›²: [{np.min(train_scores):.3f}, {np.max(train_scores):.3f}]")
        
        return train_scores
    
    def predict_malignancy(self, image_path):
        """æ‚ªæ€§ã‚‰ã—ã•äºˆæ¸¬"""
        # ç‰¹å¾´æŠ½å‡º
        features = self.extract_features_from_image(image_path)
        if features is None:
            return None
        
        # æ­£è¦åŒ–
        features_scaled = self.scaler.transform(features.reshape(1, -1))
        
        # æ‚ªæ€§ã‚‰ã—ã•ã‚¹ã‚³ã‚¢è¨ˆç®—
        malignancy_score = self.anomaly_detector.decision_function(features_scaled)[0]
        
        # ç•°å¸¸æ¤œçŸ¥çµæœï¼ˆ-1: ç•°å¸¸/è‰¯æ€§, 1: æ­£å¸¸/æ‚ªæ€§ï¼‰
        anomaly_prediction = self.anomaly_detector.predict(features_scaled)[0]
        
        # ç¢ºç‡çš„è§£é‡ˆï¼ˆ0-1ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
        # ã‚¹ã‚³ã‚¢ãŒé«˜ã„ã»ã©æ‚ªæ€§ã‚‰ã—ã„
        normalized_score = (malignancy_score - self.malignancy_threshold) / \
                          (np.abs(self.malignancy_threshold) + 1e-8)
        malignancy_probability = 1 / (1 + np.exp(-normalized_score))  # ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°
        
        # æœ€çµ‚åˆ¤å®š
        is_malignant = malignancy_score > self.malignancy_threshold
        confidence = malignancy_probability if is_malignant else (1 - malignancy_probability)
        
        return {
            'malignancy_score': malignancy_score,
            'malignancy_probability': malignancy_probability,
            'benign_probability': 1 - malignancy_probability,
            'predicted_type': 'malignant' if is_malignant else 'benign',
            'predicted_class': 1 if is_malignant else 0,
            'confidence': confidence,
            'anomaly_prediction': anomaly_prediction,
            'threshold': self.malignancy_threshold
        }
    
    def save_model(self, save_path):
        """ãƒ¢ãƒ‡ãƒ«ä¿å­˜"""
        model_data = {
            'feature_extractor_state': self.feature_extractor.state_dict(),
            'anomaly_detector': self.anomaly_detector,
            'scaler': self.scaler,
            'malignancy_threshold': self.malignancy_threshold,
            'training_stats': self.training_stats,
            'timestamp': datetime.now().isoformat()
        }
        
        with open(save_path, 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: {save_path}")
    
    def load_model(self, load_path):
        """ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿"""
        if not os.path.exists(load_path):
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {load_path}")
            return False
        
        with open(load_path, 'rb') as f:
            model_data = pickle.load(f)
        
        # ç‰¹å¾´æŠ½å‡ºå™¨ã®å¾©å…ƒ
        self.feature_extractor = FeatureExtractor()
        self.feature_extractor.load_state_dict(model_data['feature_extractor_state'])
        self.feature_extractor.to(device)
        self.feature_extractor.eval()
        
        # ãã®ä»–ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå¾©å…ƒ
        self.anomaly_detector = model_data['anomaly_detector']
        self.scaler = model_data['scaler']
        self.malignancy_threshold = model_data['malignancy_threshold']
        self.training_stats = model_data['training_stats']
        
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {load_path}")
        print(f"   è¨“ç·´ç”»åƒæ•°: {self.training_stats['total_images']}")
        print(f"   ç‰¹å¾´æ¬¡å…ƒ: {self.training_stats['feature_dimension']}")
        
        return True

def train_one_class_system():
    """ä¸€ã‚¯ãƒ©ã‚¹åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ã®è¨“ç·´"""
    print("ğŸš€ ä¸€ã‚¯ãƒ©ã‚¹æ‚ªæ€§æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ è¨“ç·´é–‹å§‹")
    print("=" * 60)
    
    detector = OneClassMalignancyDetector()
    
    # ç‰¹å¾´æŠ½å‡ºå™¨ã®åˆæœŸåŒ–
    detector.feature_extractor = FeatureExtractor()
    detector.feature_extractor.to(device)
    detector.feature_extractor.eval()
    
    # æ‚ªæ€§ç”»åƒã‹ã‚‰ç‰¹å¾´åé›†
    features, image_paths, disease_labels = detector.collect_malignant_features()
    
    if len(features) == 0:
        print("âŒ æ‚ªæ€§ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return None
    
    # ç•°å¸¸æ¤œçŸ¥å™¨ã®è¨“ç·´
    train_scores = detector.train_anomaly_detector(features, method='isolation_forest')
    
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    model_path = '/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢/one_class_malignancy_detector.pkl'
    detector.save_model(model_path)
    
    # è¨“ç·´çµ±è¨ˆã®ä¿å­˜
    stats_path = '/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢/one_class_training_stats.json'
    with open(stats_path, 'w', encoding='utf-8') as f:
        json.dump({
            'training_stats': detector.training_stats,
            'threshold': float(detector.malignancy_threshold),
            'score_statistics': {
                'mean': float(np.mean(train_scores)),
                'std': float(np.std(train_scores)),
                'min': float(np.min(train_scores)),
                'max': float(np.max(train_scores))
            }
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“Š è¨“ç·´å®Œäº†çµ±è¨ˆ:")
    for disease, count in detector.training_stats['diseases'].items():
        print(f"   {disease}: {count}æš")
    
    return detector

def test_one_class_system():
    """ä¸€ã‚¯ãƒ©ã‚¹åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ§ª ä¸€ã‚¯ãƒ©ã‚¹åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    detector = OneClassMalignancyDetector()
    model_path = '/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢/one_class_malignancy_detector.pkl'
    
    if not detector.load_model(model_path):
        return
    
    # ãƒ†ã‚¹ãƒˆç”»åƒ
    test_image = '/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢/images.jpeg'
    
    if not os.path.exists(test_image):
        print(f"âŒ ãƒ†ã‚¹ãƒˆç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {test_image}")
        return
    
    print(f"\nğŸ“‚ ãƒ†ã‚¹ãƒˆå¯¾è±¡: {os.path.basename(test_image)}")
    print("ğŸ” ä¸€ã‚¯ãƒ©ã‚¹åˆ†é¡å®Ÿè¡Œä¸­...")
    
    # äºˆæ¸¬å®Ÿè¡Œ
    result = detector.predict_malignancy(test_image)
    
    if result is None:
        print("âŒ äºˆæ¸¬ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    # çµæœè¡¨ç¤º
    print(f"\n" + "=" * 60)
    print("ğŸ¯ ä¸€ã‚¯ãƒ©ã‚¹åˆ†é¡çµæœ")
    print("=" * 60)
    
    prediction_jp = "æ‚ªæ€§" if result['predicted_type'] == 'malignant' else "è‰¯æ€§"
    print(f"ğŸ“Š åˆ¤å®š: {prediction_jp} ({result['predicted_type'].upper()})")
    print(f"ğŸ¯ ç¢ºä¿¡åº¦: {result['confidence']:.1%}")
    
    print(f"\nğŸ“ˆ è©³ç´°ã‚¹ã‚³ã‚¢:")
    print(f"   æ‚ªæ€§ã‚‰ã—ã•ã‚¹ã‚³ã‚¢: {result['malignancy_score']:.3f}")
    print(f"   æ‚ªæ€§ç¢ºç‡: {result['malignancy_probability']:.1%}")
    print(f"   è‰¯æ€§ç¢ºç‡: {result['benign_probability']:.1%}")
    print(f"   åˆ¤å®šé–¾å€¤: {result['threshold']:.3f}")
    
    # è§£é‡ˆ
    print(f"\nğŸ’¡ çµæœè§£é‡ˆ:")
    if result['malignancy_score'] > result['threshold']:
        margin = result['malignancy_score'] - result['threshold']
        print(f"   âœ… æ‚ªæ€§ã‚‰ã—ã•ãŒé–¾å€¤ã‚’{margin:.3f}ä¸Šå›ã£ã¦ã„ã¾ã™")
        print(f"   ğŸ”¬ æ‚ªæ€§ã®ç‰¹å¾´ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨é¡ä¼¼ã—ã¦ã„ã¾ã™")
    else:
        margin = result['threshold'] - result['malignancy_score']
        print(f"   âœ… æ‚ªæ€§ã‚‰ã—ã•ãŒé–¾å€¤ã‚’{margin:.3f}ä¸‹å›ã£ã¦ã„ã¾ã™")
        print(f"   ğŸŒ¿ æ‚ªæ€§ã®ç‰¹å¾´ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã¯ç•°ãªã‚Šã¾ã™")
    
    # å¾“æ¥æ‰‹æ³•ã¨ã®æ¯”è¼ƒç”¨ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    comparison_data = {
        'one_class_result': result,
        'test_image': test_image,
        'timestamp': datetime.now().isoformat()
    }
    
    with open('/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢/one_class_test_result.json', 'w', encoding='utf-8') as f:
        # numpyå‹ã‚’é€šå¸¸ã®Pythonå‹ã«å¤‰æ›
        def convert_numpy(obj):
            if isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            return obj
        
        json.dump(comparison_data, f, indent=2, ensure_ascii=False, default=convert_numpy)

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸ”¬ ä¸€ã‚¯ãƒ©ã‚¹æ‚ªæ€§æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ")
    print("   æ‚ªæ€§ç”»åƒã®ã¿ã§å­¦ç¿’ã™ã‚‹è‰¯æ€§ãƒ»æ‚ªæ€§åˆ¤åˆ¥")
    print("=" * 60)
    
    # è¨“ç·´å®Ÿè¡Œ
    detector = train_one_class_system()
    
    if detector is None:
        return
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_one_class_system()

if __name__ == "__main__":
    main()