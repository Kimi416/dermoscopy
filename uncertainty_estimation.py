"""
ä¸ç¢ºå®Ÿæ€§æ¨å®šã‚·ã‚¹ãƒ†ãƒ 
SKèª¤åˆ†é¡å¯¾ç­–ã®ãŸã‚ã®ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆå®Ÿè£…
"""

import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision.models import efficientnet_v2_s
from PIL import Image
import numpy as np
import os
from scipy import stats
import matplotlib.pyplot as plt

# ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')

class UncertaintyModel(nn.Module):
    """ä¸ç¢ºå®Ÿæ€§æ¨å®šå¯¾å¿œãƒ¢ãƒ‡ãƒ«"""
    
    def __init__(self, num_classes=2, dropout_rate=0.3):
        super().__init__()
        self.backbone = efficientnet_v2_s(weights='IMAGENET1K_V1')
        num_features = self.backbone.classifier[1].in_features
        
        self.backbone.classifier = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(num_features, 512),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(256, num_classes)
        )
    
    def forward(self, x):
        return self.backbone(x)
    
    def enable_dropout(self):
        """æ¨è«–æ™‚ã«ã‚‚ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’æœ‰åŠ¹åŒ–"""
        for module in self.modules():
            if isinstance(module, nn.Dropout):
                module.train()
    
    def monte_carlo_predict(self, x, n_samples=50):
        """ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆäºˆæ¸¬"""
        self.eval()
        self.enable_dropout()  # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã®ã¿æœ‰åŠ¹åŒ–
        
        predictions = []
        
        with torch.no_grad():
            for _ in range(n_samples):
                output = self(x)
                probabilities = torch.softmax(output, dim=1)
                predictions.append(probabilities.cpu().numpy())
        
        predictions = np.array(predictions)  # [n_samples, batch_size, n_classes]
        return predictions

def load_model():
    """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"""
    model_path = '/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢/disease_classification_model.pth'
    
    if not os.path.exists(model_path):
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")
        return None
    
    model = UncertaintyModel(num_classes=2, dropout_rate=0.3)
    checkpoint = torch.load(model_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    
    print(f"âœ… ä¸ç¢ºå®Ÿæ€§æ¨å®šãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    return model

def preprocess_image(image_path):
    """ç”»åƒã®å‰å‡¦ç†"""
    transform = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    try:
        image = Image.open(image_path).convert('RGB')
        image_tensor = transform(image).unsqueeze(0)
        return image_tensor
    except Exception as e:
        print(f"âŒ ç”»åƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def calculate_uncertainty_metrics(predictions):
    """ä¸ç¢ºå®Ÿæ€§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—"""
    # predictions: [n_samples, batch_size, n_classes]
    predictions = predictions[:, 0, :]  # ãƒãƒƒãƒã‚µã‚¤ã‚º1ã‚’ä»®å®š
    
    # å¹³å‡äºˆæ¸¬
    mean_prediction = np.mean(predictions, axis=0)
    
    # äºˆæ¸¬åˆ†æ•£ (Predictive Variance)
    prediction_variance = np.var(predictions, axis=0)
    
    # ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ (Predictive Entropy)
    entropy = -np.sum(mean_prediction * np.log(mean_prediction + 1e-8))
    
    # ç›¸äº’æƒ…å ±é‡ (Mutual Information)
    # E[H[y|x,Î¸]] - H[E[y|x,D]]
    individual_entropies = [-np.sum(pred * np.log(pred + 1e-8)) for pred in predictions]
    expected_entropy = np.mean(individual_entropies)
    mutual_information = entropy - expected_entropy
    
    # åˆ†æ•£æ¯” (Variation Ratio) - æœ€é »å€¤ä»¥å¤–ã®äºˆæ¸¬é »åº¦
    predicted_classes = np.argmax(predictions, axis=1)
    mode_count = np.max(np.bincount(predicted_classes))
    variation_ratio = 1 - (mode_count / len(predictions))
    
    return {
        'mean_prediction': mean_prediction,
        'prediction_variance': prediction_variance,
        'entropy': entropy,
        'mutual_information': mutual_information,
        'variation_ratio': variation_ratio,
        'predictions': predictions
    }

def predict_with_uncertainty(model, image_path, n_samples=50):
    """ä¸ç¢ºå®Ÿæ€§ã‚’å«ã‚€äºˆæ¸¬"""
    image_tensor = preprocess_image(image_path)
    if image_tensor is None:
        return None
    
    image_tensor = image_tensor.to(device)
    
    # ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­äºˆæ¸¬
    print(f"ğŸ² ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®Ÿè¡Œä¸­... (n={n_samples})")
    predictions = model.monte_carlo_predict(image_tensor, n_samples)
    
    # ä¸ç¢ºå®Ÿæ€§ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
    uncertainty_metrics = calculate_uncertainty_metrics(predictions)
    
    # åŸºæœ¬çš„ãªçµæœ
    mean_pred = uncertainty_metrics['mean_prediction']
    benign_prob = mean_pred[0]
    malignant_prob = mean_pred[1]
    predicted_class = 1 if malignant_prob > benign_prob else 0
    confidence = max(benign_prob, malignant_prob)
    
    # ä¿¡é ¼æ€§è©•ä¾¡
    high_uncertainty = uncertainty_metrics['entropy'] > 0.5  # é–¾å€¤ã¯èª¿æ•´å¯èƒ½
    high_variance = np.max(uncertainty_metrics['prediction_variance']) > 0.1
    low_consensus = uncertainty_metrics['variation_ratio'] > 0.3
    
    reliability_flags = {
        'high_uncertainty': high_uncertainty,
        'high_variance': high_variance, 
        'low_consensus': low_consensus
    }
    
    # ç·åˆçš„ãªä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢
    reliability_issues = sum(reliability_flags.values())
    reliability_score = max(0, 1 - (reliability_issues / 3))  # 0-1ã‚¹ã‚±ãƒ¼ãƒ«
    
    return {
        'predicted_class': predicted_class,
        'predicted_type': 'malignant' if predicted_class == 1 else 'benign',
        'confidence': confidence,
        'benign_probability': benign_prob,
        'malignant_probability': malignant_prob,
        'uncertainty_metrics': uncertainty_metrics,
        'reliability_flags': reliability_flags,
        'reliability_score': reliability_score,
        'n_samples': n_samples
    }

def analyze_prediction_distribution(result):
    """äºˆæ¸¬åˆ†å¸ƒã®åˆ†æ"""
    predictions = result['uncertainty_metrics']['predictions']
    
    print(f"\nğŸ“Š äºˆæ¸¬åˆ†å¸ƒåˆ†æ:")
    print("-" * 40)
    
    # ã‚¯ãƒ©ã‚¹åˆ¥äºˆæ¸¬ç¢ºç‡ã®çµ±è¨ˆ
    benign_probs = predictions[:, 0]
    malignant_probs = predictions[:, 1]
    
    print(f"è‰¯æ€§ç¢ºç‡:")
    print(f"  å¹³å‡: {np.mean(benign_probs):.3f}")
    print(f"  æ¨™æº–åå·®: {np.std(benign_probs):.3f}")
    print(f"  ç¯„å›²: [{np.min(benign_probs):.3f}, {np.max(benign_probs):.3f}]")
    
    print(f"\næ‚ªæ€§ç¢ºç‡:")
    print(f"  å¹³å‡: {np.mean(malignant_probs):.3f}")
    print(f"  æ¨™æº–åå·®: {np.std(malignant_probs):.3f}")
    print(f"  ç¯„å›²: [{np.min(malignant_probs):.3f}, {np.max(malignant_probs):.3f}]")
    
    # äºˆæ¸¬ã®ä¸€è²«æ€§
    predicted_classes = np.argmax(predictions, axis=1)
    class_counts = np.bincount(predicted_classes)
    consensus_ratio = np.max(class_counts) / len(predictions)
    
    print(f"\näºˆæ¸¬ä¸€è²«æ€§:")
    print(f"  è‰¯æ€§äºˆæ¸¬: {class_counts[0]}å› ({class_counts[0]/len(predictions):.1%})")
    print(f"  æ‚ªæ€§äºˆæ¸¬: {class_counts[1]}å› ({class_counts[1]/len(predictions):.1%})")
    print(f"  åˆæ„ç‡: {consensus_ratio:.1%}")

def generate_reliability_assessment(result):
    """ä¿¡é ¼æ€§è©•ä¾¡ã®ç”Ÿæˆ"""
    metrics = result['uncertainty_metrics']
    flags = result['reliability_flags']
    score = result['reliability_score']
    
    print(f"\nğŸ” ä¿¡é ¼æ€§è©•ä¾¡:")
    print("-" * 40)
    print(f"ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢: {score:.1%}")
    
    # ãƒ•ãƒ©ã‚°åˆ¥ã®è§£é‡ˆ
    if flags['high_uncertainty']:
        print("âš ï¸ é«˜ã„ä¸ç¢ºå®Ÿæ€§: ãƒ¢ãƒ‡ãƒ«ãŒåˆ¤å®šã«è¿·ã£ã¦ã„ã¾ã™")
    
    if flags['high_variance']:
        print("âš ï¸ é«˜ã„åˆ†æ•£: äºˆæ¸¬ãŒå®‰å®šã—ã¦ã„ã¾ã›ã‚“")
    
    if flags['low_consensus']:
        print("âš ï¸ ä½ã„åˆæ„: ã‚µãƒ³ãƒ—ãƒ«é–“ã§äºˆæ¸¬ãŒåˆ†æ•£ã—ã¦ã„ã¾ã™")
    
    # ä¸ç¢ºå®Ÿæ€§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¡¨ç¤º
    print(f"\nğŸ“ˆ ä¸ç¢ºå®Ÿæ€§ãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
    print(f"  ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: {metrics['entropy']:.3f}")
    print(f"  ç›¸äº’æƒ…å ±é‡: {metrics['mutual_information']:.3f}")
    print(f"  åˆ†æ•£æ¯”: {metrics['variation_ratio']:.3f}")
    print(f"  äºˆæ¸¬åˆ†æ•£ (è‰¯æ€§): {metrics['prediction_variance'][0]:.3f}")
    print(f"  äºˆæ¸¬åˆ†æ•£ (æ‚ªæ€§): {metrics['prediction_variance'][1]:.3f}")

def recommend_action(result):
    """æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆ"""
    score = result['reliability_score']
    predicted_type = result['predicted_type']
    confidence = result['confidence']
    
    print(f"\nğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
    print("-" * 40)
    
    if score >= 0.8:
        print("âœ… é«˜ã„ä¿¡é ¼æ€§ - åˆ¤å®šçµæœã‚’ä¿¡é ¼ã§ãã¾ã™")
        if predicted_type == 'malignant':
            print("ğŸ”¬ æ‚ªæ€§åˆ¤å®š: å°‚é–€åŒ»ã«ã‚ˆã‚‹ç¢ºèªã‚’æ¨å¥¨")
        else:
            print("ğŸ‘€ è‰¯æ€§åˆ¤å®š: å®šæœŸçš„ãªçµŒéè¦³å¯Ÿã‚’æ¨å¥¨")
    
    elif score >= 0.5:
        print("âš ï¸ ä¸­ç¨‹åº¦ã®ä¿¡é ¼æ€§ - è¿½åŠ æ¤œæŸ»ã‚’æ¤œè¨")
        print("ğŸ”„ åˆ¥è§’åº¦ã‹ã‚‰ã®æ’®å½±ç”»åƒã§ã®å†åˆ¤å®šã‚’æ¨å¥¨")
        if predicted_type == 'malignant':
            print("ğŸš¨ æ‚ªæ€§ã®å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€é€Ÿã‚„ã‹ãªå°‚é–€åŒ»å—è¨ºã‚’æ¨å¥¨")
    
    else:
        print("âŒ ä½ã„ä¿¡é ¼æ€§ - åˆ¤å®šçµæœã¯å‚è€ƒç¨‹åº¦")
        print("ğŸ¥ å°‚é–€åŒ»ã«ã‚ˆã‚‹ç›´æ¥è¨ºæ–­ã‚’å¼·ãæ¨å¥¨")
        print("ğŸ“¸ é«˜å“è³ªãªç”»åƒã§ã®å†æ’®å½±ã‚’æ¤œè¨")
    
    # ç‰¹æ®Šã‚±ãƒ¼ã‚¹: SKèª¤åˆ†é¡å¯¾ç­–
    if (predicted_type == 'malignant' and 
        confidence > 0.95 and 
        result['uncertainty_metrics']['entropy'] > 0.3):
        print("\nğŸ¯ SKèª¤åˆ†é¡ã®å¯èƒ½æ€§:")
        print("   é«˜ã„ç¢ºä¿¡åº¦ã§æ‚ªæ€§åˆ¤å®šã•ã‚Œã¦ã„ã¾ã™ãŒã€")
        print("   ä¸ç¢ºå®Ÿæ€§ã‚‚é«˜ã„ãŸã‚ã€è„‚æ¼æ€§è§’åŒ–ç—‡(SK)ã®")
        print("   å¯èƒ½æ€§ã‚‚è€ƒæ…®ã—ã¦å°‚é–€åŒ»ã«ã”ç›¸è«‡ãã ã•ã„")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ² ä¸ç¢ºå®Ÿæ€§æ¨å®šã«ã‚ˆã‚‹è¨ºæ–­ã‚·ã‚¹ãƒ†ãƒ ")
    print("   SKèª¤åˆ†é¡å¯¾ç­–ç‰ˆ")
    print("=" * 60)
    
    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    model = load_model()
    if model is None:
        return
    
    # è¨ºæ–­å¯¾è±¡ç”»åƒ
    image_path = '/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢/images.jpeg'
    
    if not os.path.exists(image_path):
        print(f"âŒ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_path}")
        return
    
    print(f"\nğŸ“‚ è¨ºæ–­å¯¾è±¡: {os.path.basename(image_path)}")
    
    # ä¸ç¢ºå®Ÿæ€§æ¨å®šä»˜ãäºˆæ¸¬
    result = predict_with_uncertainty(model, image_path, n_samples=100)
    
    if result is None:
        print("âŒ è¨ºæ–­ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    # çµæœè¡¨ç¤º
    print(f"\n" + "=" * 60)
    print("ğŸ¯ è¨ºæ–­çµæœï¼ˆä¸ç¢ºå®Ÿæ€§æ¨å®šä»˜ãï¼‰")
    print("=" * 60)
    
    prediction_jp = "æ‚ªæ€§" if result['predicted_type'] == 'malignant' else "è‰¯æ€§"
    print(f"ğŸ“Š åˆ¤å®š: {prediction_jp} ({result['predicted_type'].upper()})")
    print(f"ğŸ¯ ç¢ºä¿¡åº¦: {result['confidence']:.1%}")
    print(f"ğŸ”„ ã‚µãƒ³ãƒ—ãƒ«æ•°: {result['n_samples']}å›")
    
    print(f"\nğŸ“ˆ å¹³å‡ç¢ºç‡:")
    print(f"   è‰¯æ€§: {result['benign_probability']:.1%}")
    print(f"   æ‚ªæ€§: {result['malignant_probability']:.1%}")
    
    # è©³ç´°åˆ†æ
    analyze_prediction_distribution(result)
    generate_reliability_assessment(result)
    recommend_action(result)
    
    # å‰å›ã®çµæœã¨æ¯”è¼ƒ
    print(f"\nğŸ“‹ å¾“æ¥ã‚·ã‚¹ãƒ†ãƒ ã¨ã®æ¯”è¼ƒ:")
    print("-" * 40)
    print("å‰å›: æ‚ªæ€§ 99.8%ç¢ºä¿¡åº¦ï¼ˆä¸ç¢ºå®Ÿæ€§æ¨å®šãªã—ï¼‰")
    print(f"ä»Šå›: {prediction_jp} {result['confidence']:.1%}ç¢ºä¿¡åº¦")
    print(f"ä¿¡é ¼æ€§ã‚¹ã‚³ã‚¢: {result['reliability_score']:.1%}")
    
    if result['reliability_score'] < 0.8:
        print("ğŸ’¡ ä¸ç¢ºå®Ÿæ€§æ¨å®šã«ã‚ˆã‚Šã€åˆ¤å®šã®ä¿¡é ¼æ€§ã«")
        print("   å•é¡ŒãŒã‚ã‚‹ã“ã¨ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼")

if __name__ == "__main__":
    main()