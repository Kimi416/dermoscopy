"""
HAM10000ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ”¯æ´ãƒ„ãƒ¼ãƒ«
ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çŠ¶æ³ç¢ºèªãƒ»ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ãƒ»è‡ªå‹•å±•é–‹
"""

import os
import zipfile
import hashlib
from pathlib import Path

class HAM10000DownloadHelper:
    """HAM10000ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ”¯æ´ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, data_dir="/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢/ham10000_data"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        
        # å¿…è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®å®šç¾©
        self.required_files = {
            'metadata': {
                'filename': 'HAM10000_metadata.csv',
                'expected_size_mb': 1,
                'description': 'ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆè¨ºæ–­æƒ…å ±ï¼‰'
            },
            'images_part1': {
                'filename': 'HAM10000_images_part_1.zip',
                'expected_size_mb': 2500,
                'description': 'ç”»åƒãƒ‡ãƒ¼ã‚¿ Part 1'
            },
            'images_part2': {
                'filename': 'HAM10000_images_part_2.zip', 
                'expected_size_mb': 2500,
                'description': 'ç”»åƒãƒ‡ãƒ¼ã‚¿ Part 2'
            }
        }
    
    def check_download_status(self):
        """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çŠ¶æ³ã‚’ãƒã‚§ãƒƒã‚¯"""
        
        print("=" * 60)
        print("ğŸ” HAM10000ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çŠ¶æ³ç¢ºèª")
        print("=" * 60)
        
        status = {}
        total_files = len(self.required_files)
        downloaded_files = 0
        
        for key, file_info in self.required_files.items():
            file_path = self.data_dir / file_info['filename']
            
            if file_path.exists():
                file_size_mb = file_path.stat().st_size / (1024 * 1024)
                expected_mb = file_info['expected_size_mb']
                
                if file_size_mb >= expected_mb * 0.95:  # 95%ä»¥ä¸Šãªã‚‰å®Œäº†ã¨ã¿ãªã™
                    status[key] = {
                        'status': 'âœ… å®Œäº†',
                        'size_mb': file_size_mb,
                        'path': str(file_path)
                    }
                    downloaded_files += 1
                else:
                    status[key] = {
                        'status': 'âš ï¸ ä¸å®Œå…¨',
                        'size_mb': file_size_mb,
                        'expected_mb': expected_mb,
                        'path': str(file_path)
                    }
            else:
                status[key] = {
                    'status': 'âŒ æœªãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰',
                    'expected_mb': file_info['expected_size_mb'],
                    'path': str(file_path)
                }
        
        # çŠ¶æ³è¡¨ç¤º
        for key, file_info in self.required_files.items():
            file_status = status[key]
            print(f"\\nğŸ“ {file_info['description']}:")
            print(f"   ãƒ•ã‚¡ã‚¤ãƒ«å: {file_info['filename']}")
            print(f"   çŠ¶æ³: {file_status['status']}")
            
            if 'size_mb' in file_status:
                print(f"   ã‚µã‚¤ã‚º: {file_status['size_mb']:.1f} MB")
                if 'expected_mb' in file_status:
                    print(f"   æœŸå¾…ã‚µã‚¤ã‚º: {file_status['expected_mb']} MB")
            
            print(f"   ãƒ‘ã‚¹: {file_status['path']}")
        
        print(f"\\nğŸ“Š é€²è¡ŒçŠ¶æ³: {downloaded_files}/{total_files} ãƒ•ã‚¡ã‚¤ãƒ«å®Œäº†")
        print(f"å®Œäº†ç‡: {downloaded_files/total_files:.1%}")
        
        return status, downloaded_files == total_files
    
    def extract_zip_files(self):
        """ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’å±•é–‹"""
        
        print("\\nğŸ“¦ ZIPãƒ•ã‚¡ã‚¤ãƒ«å±•é–‹ä¸­...")
        
        zip_files = ['HAM10000_images_part_1.zip', 'HAM10000_images_part_2.zip']
        
        for zip_filename in zip_files:
            zip_path = self.data_dir / zip_filename
            extract_dir = self.data_dir / zip_filename.replace('.zip', '')
            
            if not zip_path.exists():
                print(f"âš ï¸ {zip_filename} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                continue
            
            if extract_dir.exists() and any(extract_dir.iterdir()):
                print(f"âœ… {zip_filename} ã¯æ—¢ã«å±•é–‹æ¸ˆã¿")
                continue
            
            print(f"ğŸ“¦ {zip_filename} ã‚’å±•é–‹ä¸­...")
            
            try:
                with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                    zip_ref.extractall(self.data_dir)
                print(f"âœ… {zip_filename} å±•é–‹å®Œäº†")
                
                # å±•é–‹å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«æ•°ç¢ºèª
                if extract_dir.exists():
                    file_count = len([f for f in extract_dir.iterdir() if f.is_file()])
                    print(f"   å±•é–‹ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°: {file_count}")
                
            except Exception as e:
                print(f"âŒ {zip_filename} å±•é–‹ã‚¨ãƒ©ãƒ¼: {e}")
    
    def verify_dataset_integrity(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ•´åˆæ€§ç¢ºèª"""
        
        print("\\nğŸ” ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ•´åˆæ€§ç¢ºèª...")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç¢ºèª
        metadata_path = self.data_dir / 'HAM10000_metadata.csv'
        if metadata_path.exists():
            try:
                import pandas as pd
                df = pd.read_csv(metadata_path)
                print(f"âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {len(df)} ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰")
                print(f"   åˆ—: {', '.join(df.columns.tolist())}")
                
                # è¨ºæ–­åˆ†å¸ƒç¢ºèª
                if 'dx' in df.columns:
                    diagnosis_counts = df['dx'].value_counts()
                    print("\\nğŸ“Š è¨ºæ–­åˆ†å¸ƒ:")
                    for dx, count in diagnosis_counts.items():
                        print(f"   {dx}: {count}ä»¶")
                
            except Exception as e:
                print(f"âŒ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
        image_dirs = [
            self.data_dir / 'HAM10000_images_part_1',
            self.data_dir / 'HAM10000_images_part_2'
        ]
        
        total_images = 0
        for img_dir in image_dirs:
            if img_dir.exists():
                jpg_files = list(img_dir.glob('*.jpg'))
                total_images += len(jpg_files)
                print(f"âœ… {img_dir.name}: {len(jpg_files)} æšã®ç”»åƒ")
        
        print(f"\\nğŸ“Š ç·ç”»åƒæ•°: {total_images} æš")
        print(f"æœŸå¾…å€¤: 10,015 æš")
        
        if total_images >= 10000:
            print("âœ… ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå®Œäº†!")
            return True
        else:
            print("âš ï¸ ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒä¸å®Œå…¨ã§ã™")
            return False
    
    def create_download_urls(self):
        """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰URLã¨æ‰‹é †ã‚’è¡¨ç¤º"""
        
        print("\\nğŸ”— HAM10000ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯")
        print("=" * 60)
        
        print("ğŸ“‹ å…¬å¼ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒšãƒ¼ã‚¸:")
        print("https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T")
        
        print("\\nğŸ“ å¿…è¦ãƒ•ã‚¡ã‚¤ãƒ«:")
        for key, file_info in self.required_files.items():
            print(f"  â€¢ {file_info['filename']} ({file_info['expected_size_mb']} MB)")
            print(f"    â†’ {file_info['description']}")
        
        print("\\nğŸš€ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¾Œã®æ‰‹é †:")
        print("1. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã™ã¹ã¦ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®:")
        print(f"   {self.data_dir}")
        print("2. ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å†å®Ÿè¡Œã—ã¦æ•´åˆæ€§ç¢ºèª:")
        print("   python3 ham10000_download_helper.py")
        print("3. HAM10000å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ:")
        print("   python3 ham10000_pretrain_pipeline.py")
    
    def setup_directory_structure(self):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        
        print(f"\\nğŸ—ï¸ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—...")
        
        # å¿…è¦ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        directories = [
            'HAM10000_images_part_1',
            'HAM10000_images_part_2', 
            'processed',
            'benign',
            'malignant'
        ]
        
        for dir_name in directories:
            dir_path = self.data_dir / dir_name
            dir_path.mkdir(exist_ok=True)
            print(f"ğŸ“ {dir_name}")
        
        print("âœ… ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ æº–å‚™å®Œäº†")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    print("ğŸ”¬ HAM10000ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ”¯æ´ãƒ„ãƒ¼ãƒ«")
    print("=" * 60)
    
    helper = HAM10000DownloadHelper()
    
    # 1. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    helper.setup_directory_structure()
    
    # 2. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çŠ¶æ³ç¢ºèª
    status, is_complete = helper.check_download_status()
    
    if is_complete:
        print("\\nğŸ‰ ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã§ã™!")
        
        # 3. ZIPãƒ•ã‚¡ã‚¤ãƒ«å±•é–‹
        helper.extract_zip_files()
        
        # 4. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ•´åˆæ€§ç¢ºèª
        if helper.verify_dataset_integrity():
            print("\\nâœ… HAM10000ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™å®Œäº†!")
            print("\\nğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
            print("   python3 ham10000_pretrain_pipeline.py")
        else:
            print("\\nâš ï¸ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’æ¨å¥¨ã€‚")
    
    else:
        print("\\nğŸ“¥ ã¾ã ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå¿…è¦ã§ã™")
        helper.create_download_urls()
        
        print("\\nğŸ’¡ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã®ã‚³ãƒ„:")
        print("â€¢ å®‰å®šã—ãŸã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ä½¿ç”¨")
        print("â€¢ å¤œé–“ãªã©ã€ã‚µãƒ¼ãƒãƒ¼è² è·ãŒå°‘ãªã„æ™‚é–“å¸¯")
        print("â€¢ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’1ã¤ãšã¤ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        print("â€¢ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†å¾Œã¯åˆ¥ã®å ´æ‰€ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—")

if __name__ == "__main__":
    main()