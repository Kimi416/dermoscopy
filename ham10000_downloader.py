"""
HAM10000ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼
Human Against Machine with 10,000 training images

HAM10000ã¯çš®è†šç§‘åŒ»ãŒæ¤œè¨¼æ¸ˆã¿ã®é«˜å“è³ªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼š
- ç·æ•°: 10,015æš
- 7ã‚¯ãƒ©ã‚¹åˆ†é¡
- çš®è†šç§‘å°‚é–€åŒ»ã«ã‚ˆã‚‹è¨ºæ–­ç¢ºèªæ¸ˆã¿
"""

import os
import pandas as pd
import requests
import zipfile
from pathlib import Path
from tqdm import tqdm
import time

class HAM10000Downloader:
    """HAM10000ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼"""
    
    def __init__(self, output_dir="ham10000_data"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # HAM10000ã®7ã‚¯ãƒ©ã‚¹åˆ†é¡
        self.classes = {
            'akiec': 'Actinic keratoses',           # æ—¥å…‰è§’åŒ–ç—‡ï¼ˆæ‚ªæ€§å‰é§†ç—…å¤‰ï¼‰
            'bcc': 'Basal cell carcinoma',          # åŸºåº•ç´°èƒç™Œï¼ˆæ‚ªæ€§ï¼‰
            'bkl': 'Benign keratosis-like lesions', # è‰¯æ€§è§’åŒ–ç—‡æ§˜ç—…å¤‰ï¼ˆè‰¯æ€§ï¼‰
            'df': 'Dermatofibroma',                 # çš®è†šç·šç¶­è…«ï¼ˆè‰¯æ€§ï¼‰
            'mel': 'Melanoma',                      # ãƒ¡ãƒ©ãƒãƒ¼ãƒï¼ˆæ‚ªæ€§ï¼‰
            'nv': 'Melanocytic nevi',               # è‰²ç´ æ€§æ¯æ–‘ï¼ˆè‰¯æ€§ï¼‰
            'vasc': 'Vascular lesions'              # è¡€ç®¡ç—…å¤‰ï¼ˆè‰¯æ€§ï¼‰
        }
        
        # è‰¯æ€§ãƒ»æ‚ªæ€§åˆ†é¡
        self.benign_classes = ['bkl', 'df', 'nv', 'vasc']
        self.malignant_classes = ['akiec', 'bcc', 'mel']
        
        print("ğŸ”¬ HAM10000ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆæœŸåŒ–")
        print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir}")
        print(f"ğŸ“Š ã‚¯ãƒ©ã‚¹æ•°: {len(self.classes)}")
        print(f"âœ… è‰¯æ€§ã‚¯ãƒ©ã‚¹: {len(self.benign_classes)}å€‹")
        print(f"âŒ æ‚ªæ€§ã‚¯ãƒ©ã‚¹: {len(self.malignant_classes)}å€‹")
    
    def download_dataset(self):
        """HAM10000ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        
        print("\\nğŸ“¥ HAM10000ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹...")
        
        # Kaggle HAM10000ã®URLï¼ˆè¦èªè¨¼ï¼‰
        urls = {
            'metadata': 'https://dataverse.harvard.edu/api/access/datafile/3450625',
            'images_part1': 'https://dataverse.harvard.edu/api/access/datafile/3450626',
            'images_part2': 'https://dataverse.harvard.edu/api/access/datafile/3450627'
        }
        
        print("âš ï¸ HAM10000ã¯èªè¨¼ãŒå¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚")
        print("ğŸ“‹ æ‰‹å‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ‰‹é †:")
        print("1. https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T")
        print("2. HAM10000_metadata.csv ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        print("3. HAM10000_images_part_1.zip ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰") 
        print("4. HAM10000_images_part_2.zip ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        print(f"5. ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ {self.output_dir} ã«é…ç½®")
        
        return False
    
    def setup_demo_structure(self):
        """ãƒ‡ãƒ¢ç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ"""
        
        print("\\nğŸ—ï¸ HAM10000ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ...")
        
        # 7ã‚¯ãƒ©ã‚¹ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        for class_code, class_name in self.classes.items():
            class_dir = self.output_dir / class_code
            class_dir.mkdir(exist_ok=True)
            print(f"ğŸ“ {class_code}: {class_name}")
        
        # è‰¯æ€§ãƒ»æ‚ªæ€§ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª  
        (self.output_dir / "benign").mkdir(exist_ok=True)
        (self.output_dir / "malignant").mkdir(exist_ok=True)
        
        print(f"âœ… ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆå®Œäº†: {self.output_dir}")
        
        return True
    
    def create_binary_classification_map(self):
        """7ã‚¯ãƒ©ã‚¹â†’2ã‚¯ãƒ©ã‚¹ï¼ˆè‰¯æ€§ãƒ»æ‚ªæ€§ï¼‰ãƒãƒƒãƒ”ãƒ³ã‚°ä½œæˆ"""
        
        classification_map = {}
        
        # è‰¯æ€§ã‚¯ãƒ©ã‚¹
        for class_code in self.benign_classes:
            classification_map[class_code] = {
                'binary_label': 0,  # è‰¯æ€§
                'category': 'benign',
                'description': self.classes[class_code]
            }
        
        # æ‚ªæ€§ã‚¯ãƒ©ã‚¹
        for class_code in self.malignant_classes:
            classification_map[class_code] = {
                'binary_label': 1,  # æ‚ªæ€§ 
                'category': 'malignant',
                'description': self.classes[class_code]
            }
        
        # ãƒãƒƒãƒ”ãƒ³ã‚°ä¿å­˜
        import json
        map_file = self.output_dir / "binary_classification_map.json"
        with open(map_file, 'w', encoding='utf-8') as f:
            json.dump(classification_map, f, indent=2, ensure_ascii=False)
        
        print(f"\\nğŸ“‹ 2ã‚¯ãƒ©ã‚¹åˆ†é¡ãƒãƒƒãƒ—ä½œæˆ: {map_file}")
        print("\\nğŸ·ï¸ ã‚¯ãƒ©ã‚¹åˆ†é¡:")
        print("è‰¯æ€§ (benign = 0):")
        for code in self.benign_classes:
            print(f"  â€¢ {code}: {self.classes[code]}")
        print("\\næ‚ªæ€§ (malignant = 1):")
        for code in self.malignant_classes:
            print(f"  â€¢ {code}: {self.classes[code]}")
        
        return classification_map
    
    def analyze_dataset_balance(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒãƒ©ãƒ³ã‚¹åˆ†æï¼ˆç†è«–å€¤ï¼‰"""
        
        # HAM10000ã®ç†è«–çš„ãªåˆ†å¸ƒ
        theoretical_distribution = {
            'nv': 6705,      # è‰²ç´ æ€§æ¯æ–‘ï¼ˆè‰¯æ€§ï¼‰
            'mel': 1113,     # ãƒ¡ãƒ©ãƒãƒ¼ãƒï¼ˆæ‚ªæ€§ï¼‰
            'bkl': 1099,     # è‰¯æ€§è§’åŒ–ç—‡ï¼ˆè‰¯æ€§ï¼‰
            'bcc': 514,      # åŸºåº•ç´°èƒç™Œï¼ˆæ‚ªæ€§ï¼‰
            'akiec': 327,    # æ—¥å…‰è§’åŒ–ç—‡ï¼ˆæ‚ªæ€§å‰é§†ï¼‰
            'vasc': 142,     # è¡€ç®¡ç—…å¤‰ï¼ˆè‰¯æ€§ï¼‰
            'df': 115        # çš®è†šç·šç¶­è…«ï¼ˆè‰¯æ€§ï¼‰
        }
        
        benign_count = sum(theoretical_distribution[code] for code in self.benign_classes)
        malignant_count = sum(theoretical_distribution[code] for code in self.malignant_classes)
        total_count = benign_count + malignant_count
        
        print(f"\\nğŸ“Š HAM10000ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†å¸ƒï¼ˆç†è«–å€¤ï¼‰:")
        print(f"ç·æ•°: {total_count:,}æš")
        print(f"\\nè‰¯æ€§: {benign_count:,}æš ({benign_count/total_count:.1%})")
        for code in self.benign_classes:
            count = theoretical_distribution[code]
            print(f"  â€¢ {code}: {count:,}æš ({count/total_count:.1%}) - {self.classes[code]}")
        
        print(f"\\næ‚ªæ€§: {malignant_count:,}æš ({malignant_count/total_count:.1%})")
        for code in self.malignant_classes:
            count = theoretical_distribution[code]
            print(f"  â€¢ {code}: {count:,}æš ({count/total_count:.1%}) - {self.classes[code]}")
        
        print(f"\\nâš–ï¸ è‰¯æ€§:æ‚ªæ€§æ¯”ç‡ = {benign_count/malignant_count:.1f}:1")
        
        return theoretical_distribution

def main():
    """HAM10000ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    print("=" * 60)
    print("ğŸ”¬ HAM10000ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—")
    print("=" * 60)
    
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼åˆæœŸåŒ–
    downloader = HAM10000Downloader()
    
    # 1. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ
    downloader.setup_demo_structure()
    
    # 2. 2ã‚¯ãƒ©ã‚¹åˆ†é¡ãƒãƒƒãƒ—ä½œæˆ
    downloader.create_binary_classification_map()
    
    # 3. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ†å¸ƒåˆ†æ
    downloader.analyze_dataset_balance()
    
    # 4. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¡ˆå†…
    downloader.download_dataset()
    
    print("\\nâœ… HAM10000ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†!")
    print("\\nğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("1. æ‰‹å‹•ã§HAM10000ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    print("2. ham10000_pretrain_pipeline.py ã§å­¦ç¿’é–‹å§‹")
    print("3. ISICç‰ˆã¨æ€§èƒ½æ¯”è¼ƒ")

if __name__ == "__main__":
    main()