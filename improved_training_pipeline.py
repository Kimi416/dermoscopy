"""
éå­¦ç¿’å¯¾ç­–ç‰ˆ HAM10000ãƒ€ãƒ¼ãƒ¢ã‚¹ã‚³ãƒ”ãƒ¼åˆ†é¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
Data Augmentation + æ­£å‰‡åŒ– + Early Stopping + Cross-Validation
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torchvision.models import efficientnet_v2_s
from torch.utils.data import Dataset, DataLoader, random_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score
import pandas as pd
import numpy as np
from PIL import Image
import os
import glob
from pathlib import Path
import matplotlib.pyplot as plt
import copy
import time

# ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')
print(f"ğŸ–¥ï¸ ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")

class ImprovedDermoscopyModel(nn.Module):
    """æ”¹å–„ç‰ˆãƒ€ãƒ¼ãƒ¢ã‚¹ã‚³ãƒ”ãƒ¼åˆ†é¡ãƒ¢ãƒ‡ãƒ«ï¼ˆéå­¦ç¿’å¯¾ç­–æ¸ˆã¿ï¼‰"""
    
    def __init__(self, num_classes=2, dropout_rate=0.5):
        super().__init__()
        # EfficientNet-v2-S ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³
        self.backbone = efficientnet_v2_s(weights='IMAGENET1K_V1')
        num_features = self.backbone.classifier[1].in_features
        
        # æ”¹å–„ã•ã‚ŒãŸãƒ˜ãƒƒãƒ‰ï¼ˆã‚ˆã‚Šå¼·ã„æ­£å‰‡åŒ–ï¼‰
        self.backbone.classifier = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(num_features, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(256, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(dropout_rate * 0.7),  # æœ€çµ‚å±¤ã¯å°‘ã—å¼±ã‚
            nn.Linear(128, num_classes)
        )
        
        # Backbone ã®ä¸€éƒ¨ã‚’å‡çµï¼ˆéå­¦ç¿’é˜²æ­¢ï¼‰
        self._freeze_early_layers()
    
    def _freeze_early_layers(self):
        """åˆæœŸå±¤ã‚’å‡çµã—ã¦éå­¦ç¿’ã‚’é˜²æ­¢"""
        # æœ€åˆã®2ã¤ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’å‡çµ
        for i, (name, param) in enumerate(self.backbone.features.named_parameters()):
            if i < 10:  # æœ€åˆã®10å±¤ã‚’å‡çµ
                param.requires_grad = False
    
    def forward(self, x):
        return self.backbone(x)

class AugmentedDermoscopyDataset(Dataset):
    """å¼·åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿æ‹¡å¼µä»˜ããƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"""
    
    def __init__(self, image_paths, labels, transform=None, is_training=True):
        self.image_paths = image_paths
        self.labels = labels
        self.is_training = is_training
        
        if transform is None:
            if is_training:
                # è¨“ç·´æ™‚: å¼·åŠ›ãªãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
                self.transform = transforms.Compose([
                    transforms.Resize(256),
                    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
                    transforms.RandomHorizontalFlip(p=0.5),
                    transforms.RandomVerticalFlip(p=0.3),
                    transforms.RandomRotation(degrees=30),
                    transforms.ColorJitter(
                        brightness=0.3,
                        contrast=0.3,
                        saturation=0.3,
                        hue=0.1
                    ),
                    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),
                    transforms.RandomGrayscale(p=0.1),
                    transforms.ToTensor(),
                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
                    transforms.RandomErasing(p=0.1, scale=(0.02, 0.1))
                ])
            else:
                # æ¤œè¨¼æ™‚: åŸºæœ¬çš„ãªå‰å‡¦ç†ã®ã¿
                self.transform = transforms.Compose([
                    transforms.Resize(256),
                    transforms.CenterCrop(224),
                    transforms.ToTensor(),
                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
                ])
        else:
            self.transform = transform
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        image_path = self.image_paths[idx]
        image = Image.open(image_path).convert('RGB')
        image = self.transform(image)
        label = self.labels[idx]
        return image, label

class EarlyStopping:
    """Early Stoppingå®Ÿè£…"""
    
    def __init__(self, patience=7, min_delta=0.001, restore_best_weights=True):
        self.patience = patience
        self.min_delta = min_delta
        self.restore_best_weights = restore_best_weights
        self.best_score = None
        self.counter = 0
        self.best_weights = None
        
    def __call__(self, val_score, model):
        if self.best_score is None:
            self.best_score = val_score
            self.best_weights = copy.deepcopy(model.state_dict())
        elif val_score < self.best_score + self.min_delta:
            self.counter += 1
            if self.counter >= self.patience:
                if self.restore_best_weights:
                    model.load_state_dict(self.best_weights)
                return True
        else:
            self.best_score = val_score
            self.counter = 0
            self.best_weights = copy.deepcopy(model.state_dict())
        return False

def create_learning_rate_scheduler(optimizer, mode='cosine'):
    """å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ä½œæˆ"""
    if mode == 'cosine':
        return optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-6)
    elif mode == 'reduce':
        return optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)
    else:
        return optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)

def load_ham10000_data():
    """HAM10000ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    print("ğŸ“Š HAM10000ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    metadata_path = "/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢/ham10000_data/HAM10000_metadata.csv"
    if not os.path.exists(metadata_path):
        raise FileNotFoundError(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {metadata_path}")
    
    df = pd.read_csv(metadata_path)
    
    # ç”»åƒãƒ‘ã‚¹æ§‹ç¯‰
    image_dirs = [
        "/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢/ham10000_data/HAM10000_images_part_1",
        "/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢/ham10000_data/HAM10000_images_part_2"
    ]
    
    image_paths = []
    labels = []
    
    # 7ã‚¯ãƒ©ã‚¹ã‹ã‚‰2ã‚¯ãƒ©ã‚¹ã¸ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    benign_classes = ['bkl', 'df', 'nv', 'vasc']  # è‰¯æ€§
    malignant_classes = ['akiec', 'bcc', 'mel']   # æ‚ªæ€§
    
    for _, row in df.iterrows():
        image_id = row['image_id']
        diagnosis = row['dx']
        
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«æ¢ç´¢
        image_path = None
        for img_dir in image_dirs:
            potential_path = os.path.join(img_dir, f"{image_id}.jpg")
            if os.path.exists(potential_path):
                image_path = potential_path
                break
        
        if image_path and diagnosis in (benign_classes + malignant_classes):
            image_paths.append(image_path)
            # ãƒ©ãƒ™ãƒ«è¨­å®š: 0=è‰¯æ€§, 1=æ‚ªæ€§
            labels.append(0 if diagnosis in benign_classes else 1)
    
    print(f"âœ… HAM10000ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(image_paths)}æš")
    print(f"   è‰¯æ€§: {labels.count(0)}æš, æ‚ªæ€§: {labels.count(1)}æš")
    
    return image_paths, labels

def load_user_data():
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
    print("ğŸ“Š ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    
    # æ‚ªæ€§ãƒ‡ãƒ¼ã‚¿
    malignant_dirs = ['AK', 'BCC', 'Bowenç—…', 'MM']
    malignant_paths = []
    
    for disease in malignant_dirs:
        disease_dir = f"/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢/{disease}"
        if os.path.exists(disease_dir):
            disease_images = glob.glob(os.path.join(disease_dir, "*.jpg")) + \
                           glob.glob(os.path.join(disease_dir, "*.jpeg")) + \
                           glob.glob(os.path.join(disease_dir, "*.JPG")) + \
                           glob.glob(os.path.join(disease_dir, "*.JPEG"))
            malignant_paths.extend(disease_images)
    
    # è‰¯æ€§ãƒ‡ãƒ¼ã‚¿ (SK)
    benign_paths = []
    sk_dir = "/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢/SK"
    if os.path.exists(sk_dir):
        benign_paths = glob.glob(os.path.join(sk_dir, "*.jpg")) + \
                      glob.glob(os.path.join(sk_dir, "*.jpeg")) + \
                      glob.glob(os.path.join(sk_dir, "*.JPG")) + \
                      glob.glob(os.path.join(sk_dir, "*.JPEG"))
    
    # ãƒ‘ã‚¹ã¨ãƒ©ãƒ™ãƒ«ã‚’çµåˆ
    user_paths = malignant_paths + benign_paths
    user_labels = [1] * len(malignant_paths) + [0] * len(benign_paths)
    
    print(f"âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(user_paths)}æš")
    print(f"   è‰¯æ€§(SK): {len(benign_paths)}æš, æ‚ªæ€§: {len(malignant_paths)}æš")
    
    return user_paths, user_labels

def train_epoch(model, train_loader, criterion, optimizer, device):
    """1ã‚¨ãƒãƒƒã‚¯ã®è¨“ç·´"""
    model.train()
    total_loss = 0
    correct = 0
    total = 0
    
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        
        # å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ï¼ˆéå­¦ç¿’é˜²æ­¢ï¼‰
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        
        optimizer.step()
        
        total_loss += loss.item()
        pred = output.argmax(dim=1, keepdim=True)
        correct += pred.eq(target.view_as(pred)).sum().item()
        total += target.size(0)
    
    accuracy = 100. * correct / total
    avg_loss = total_loss / len(train_loader)
    
    return avg_loss, accuracy

def validate_epoch(model, val_loader, criterion, device):
    """1ã‚¨ãƒãƒƒã‚¯ã®æ¤œè¨¼"""
    model.eval()
    total_loss = 0
    correct = 0
    total = 0
    all_preds = []
    all_targets = []
    all_probs = []
    
    with torch.no_grad():
        for data, target in val_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            loss = criterion(output, target)
            
            total_loss += loss.item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
            total += target.size(0)
            
            # ç¢ºç‡ã¨ãƒ©ãƒ™ãƒ«ã‚’ä¿å­˜ï¼ˆAUCè¨ˆç®—ç”¨ï¼‰
            probs = torch.softmax(output, dim=1)
            all_probs.extend(probs[:, 1].cpu().numpy())  # æ‚ªæ€§ã®ç¢ºç‡
            all_preds.extend(pred.cpu().numpy())
            all_targets.extend(target.cpu().numpy())
    
    accuracy = 100. * correct / total
    avg_loss = total_loss / len(val_loader)
    
    # AUCè¨ˆç®—
    try:
        auc = roc_auc_score(all_targets, all_probs)
    except:
        auc = 0.5
    
    return avg_loss, accuracy, auc, all_targets, all_preds, all_probs

def train_with_cross_validation(ham_paths, ham_labels, user_paths, user_labels, n_folds=3):
    """Cross-Validationã‚’ä½¿ã£ãŸè¨“ç·´"""
    print(f"\nğŸ”„ {n_folds}-Fold Cross-Validationé–‹å§‹")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
    all_paths = ham_paths + user_paths
    all_labels = ham_labels + user_labels
    
    # Stratified K-Fold
    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)
    
    fold_results = []
    
    for fold, (train_idx, val_idx) in enumerate(skf.split(all_paths, all_labels)):
        print(f"\nğŸ“Š Fold {fold + 1}/{n_folds}")
        print("-" * 50)
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        train_paths = [all_paths[i] for i in train_idx]
        train_labels = [all_labels[i] for i in train_idx]
        val_paths = [all_paths[i] for i in val_idx]
        val_labels = [all_labels[i] for i in val_idx]
        
        print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(train_paths)}æš (è‰¯æ€§:{train_labels.count(0)}, æ‚ªæ€§:{train_labels.count(1)})")
        print(f"æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {len(val_paths)}æš (è‰¯æ€§:{val_labels.count(0)}, æ‚ªæ€§:{val_labels.count(1)})")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
        train_dataset = AugmentedDermoscopyDataset(train_paths, train_labels, is_training=True)
        val_dataset = AugmentedDermoscopyDataset(val_paths, val_labels, is_training=False)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆ
        train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)
        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)
        
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        model = ImprovedDermoscopyModel(num_classes=2, dropout_rate=0.5).to(device)
        
        # æå¤±é–¢æ•°ã¨ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼
        # ã‚¯ãƒ©ã‚¹é‡ã¿èª¿æ•´
        class_counts = [train_labels.count(0), train_labels.count(1)]
        class_weights = [len(train_labels) / (2 * count) for count in class_counts]
        class_weights_tensor = torch.FloatTensor(class_weights).to(device)
        
        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)
        optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)
        scheduler = create_learning_rate_scheduler(optimizer, mode='cosine')
        
        # Early Stopping
        early_stopping = EarlyStopping(patience=10, min_delta=0.001)
        
        # è¨“ç·´ãƒ«ãƒ¼ãƒ—
        best_auc = 0
        train_losses, val_losses = [], []
        train_accs, val_accs = [], []
        
        for epoch in range(50):  # æœ€å¤§50ã‚¨ãƒãƒƒã‚¯
            start_time = time.time()
            
            # è¨“ç·´
            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)
            
            # æ¤œè¨¼
            val_loss, val_acc, val_auc, val_targets, val_preds, val_probs = validate_epoch(
                model, val_loader, criterion, device
            )
            
            # å­¦ç¿’ç‡æ›´æ–°
            if isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):
                scheduler.step(val_auc)
            else:
                scheduler.step()
            
            # è¨˜éŒ²
            train_losses.append(train_loss)
            val_losses.append(val_loss)
            train_accs.append(train_acc)
            val_accs.append(val_acc)
            
            epoch_time = time.time() - start_time
            
            if (epoch + 1) % 5 == 0:  # 5ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«è¡¨ç¤º
                print(f"Epoch {epoch+1:2d}: "
                      f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.1f}% | "
                      f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.1f}%, Val AUC: {val_auc:.3f} | "
                      f"Time: {epoch_time:.1f}s")
            
            # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ä¿å­˜
            if val_auc > best_auc:
                best_auc = val_auc
                best_model_state = copy.deepcopy(model.state_dict())
            
            # Early Stopping ãƒã‚§ãƒƒã‚¯
            if early_stopping(val_auc, model):
                print(f"Early stopping at epoch {epoch+1}")
                break
        
        # Foldçµæœä¿å­˜
        fold_result = {
            'fold': fold + 1,
            'best_auc': best_auc,
            'final_val_acc': val_acc,
            'final_val_auc': val_auc,
            'val_targets': val_targets,
            'val_preds': val_preds,
            'val_probs': val_probs
        }
        fold_results.append(fold_result)
        
        print(f"Fold {fold + 1} å®Œäº†: Best AUC = {best_auc:.3f}")
        
        # Foldã”ã¨ã®ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        fold_model_path = f"/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢/improved_model_fold_{fold+1}.pth"
        torch.save({
            'model_state_dict': best_model_state,
            'fold': fold + 1,
            'best_auc': best_auc,
            'train_losses': train_losses,
            'val_losses': val_losses,
            'train_accs': train_accs,
            'val_accs': val_accs
        }, fold_model_path)
        print(f"ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {fold_model_path}")
    
    return fold_results

def evaluate_cross_validation_results(fold_results):
    """Cross-Validationçµæœã®è©•ä¾¡"""
    print("\n" + "="*60)
    print("ğŸ“Š Cross-Validation çµæœç·æ‹¬")
    print("="*60)
    
    aucs = [result['best_auc'] for result in fold_results]
    accs = [result['final_val_acc'] for result in fold_results]
    
    print(f"å¹³å‡AUC: {np.mean(aucs):.3f} Â± {np.std(aucs):.3f}")
    print(f"å¹³å‡ç²¾åº¦: {np.mean(accs):.1f}% Â± {np.std(accs):.1f}%")
    print(f"AUCç¯„å›²: {min(aucs):.3f} - {max(aucs):.3f}")
    print(f"ç²¾åº¦ç¯„å›²: {min(accs):.1f}% - {max(accs):.1f}%")
    
    # å„Foldã®è©³ç´°
    for i, result in enumerate(fold_results):
        print(f"\nFold {i+1}: AUC={result['best_auc']:.3f}, Acc={result['final_val_acc']:.1f}%")
    
    # æœ€è‰¯ã®Foldã‚’ç‰¹å®š
    best_fold = max(fold_results, key=lambda x: x['best_auc'])
    print(f"\nğŸ† æœ€è‰¯Fold: Fold {best_fold['fold']} (AUC: {best_fold['best_auc']:.3f})")
    
    return best_fold

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ”¬ éå­¦ç¿’å¯¾ç­–ç‰ˆ ãƒ€ãƒ¼ãƒ¢ã‚¹ã‚³ãƒ”ãƒ¼åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ")
    print("   Data Augmentation + æ­£å‰‡åŒ– + Early Stopping + Cross-Validation")
    print("="*80)
    
    try:
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        print("\nğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿...")
        ham_paths, ham_labels = load_ham10000_data()
        user_paths, user_labels = load_user_data()
        
        print(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:")
        print(f"HAM10000: {len(ham_paths)}æš (è‰¯æ€§:{ham_labels.count(0)}, æ‚ªæ€§:{ham_labels.count(1)})")
        print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {len(user_paths)}æš (è‰¯æ€§:{user_labels.count(0)}, æ‚ªæ€§:{user_labels.count(1)})")
        print(f"ç·è¨ˆ: {len(ham_paths) + len(user_paths)}æš")
        
        # Cross-Validationè¨“ç·´å®Ÿè¡Œ
        fold_results = train_with_cross_validation(ham_paths, ham_labels, user_paths, user_labels, n_folds=3)
        
        # çµæœè©•ä¾¡
        best_fold = evaluate_cross_validation_results(fold_results)
        
        print(f"\nâœ… æ”¹å–„ç‰ˆãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†!")
        print(f"ğŸ¯ æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: improved_model_fold_{best_fold['fold']}.pth")
        print(f"ğŸ† æœ€è‰¯AUC: {best_fold['best_auc']:.3f}")
        
        print(f"\nğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print(f"   python3 predict_improved_model.py")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()