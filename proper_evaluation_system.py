"""
é©æ­£è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 
ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯å›é¿ã«ã‚ˆã‚‹çœŸã®æ€§èƒ½è©•ä¾¡
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torchvision.models import efficientnet_v2_s, resnet50
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score, accuracy_score, classification_report, confusion_matrix
from sklearn.metrics import precision_recall_curve, average_precision_score
import numpy as np
from PIL import Image
import os
import glob
import json
from collections import defaultdict
import matplotlib.pyplot as plt
import seaborn as sns

# ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')

# ç–¾æ‚£åˆ†é¡å®šç¾©
DISEASE_MAPPING = {
    'AK': {'type': 'malignant', 'full_name': 'Actinic Keratosis'},
    'BCC': {'type': 'malignant', 'full_name': 'Basal Cell Carcinoma'}, 
    'Bowenç—…': {'type': 'malignant', 'full_name': 'Bowen Disease'},
    'MM': {'type': 'malignant', 'full_name': 'Malignant Melanoma'},
    'SK': {'type': 'benign', 'full_name': 'Seborrheic Keratosis'}
}

class DualModel(nn.Module):
    """ãƒ‡ãƒ¥ã‚¢ãƒ«ãƒ¢ãƒ‡ãƒ«ï¼ˆEfficientNet / ResNetï¼‰"""
    
    def __init__(self, model_type='efficientnet', num_classes=2, dropout_rate=0.3):
        super().__init__()
        
        if model_type == 'efficientnet':
            self.backbone = efficientnet_v2_s(weights='IMAGENET1K_V1')
            num_features = self.backbone.classifier[1].in_features
            self.backbone.classifier = nn.Sequential(
                nn.Dropout(dropout_rate),
                nn.Linear(num_features, 512),
                nn.ReLU(),
                nn.Dropout(dropout_rate),
                nn.Linear(512, num_classes)
            )
        elif model_type == 'resnet':
            self.backbone = resnet50(weights='IMAGENET1K_V1')
            num_features = self.backbone.fc.in_features
            self.backbone.fc = nn.Sequential(
                nn.Dropout(dropout_rate),
                nn.Linear(num_features, 512),
                nn.ReLU(),
                nn.Dropout(dropout_rate),
                nn.Linear(512, num_classes)
            )
    
    def forward(self, x):
        return self.backbone(x)

class EvaluationDataset(Dataset):
    """è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"""
    
    def __init__(self, image_paths, labels, patient_ids, disease_names, img_size=224, is_training=True):
        self.image_paths = image_paths
        self.labels = labels
        self.patient_ids = patient_ids
        self.disease_names = disease_names
        self.img_size = img_size
        
        if is_training:
            self.transform = transforms.Compose([
                transforms.Resize((img_size + 56, img_size + 56)),
                transforms.RandomResizedCrop(img_size, scale=(0.75, 1.0)),
                transforms.RandomHorizontalFlip(p=0.5),
                transforms.RandomRotation(degrees=15),
                transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.1),
                transforms.RandomApply([transforms.GaussianBlur(3, sigma=(0.1, 2.0))], p=0.3),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
                transforms.RandomErasing(p=0.1, scale=(0.02, 0.1))
            ])
        else:
            self.transform = transforms.Compose([
                transforms.Resize((img_size, img_size)),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        try:
            image = Image.open(self.image_paths[idx]).convert('RGB')
            image = self.transform(image)
            return image, self.labels[idx], self.patient_ids[idx], self.disease_names[idx]
        except Exception as e:
            print(f"âŒ ç”»åƒã‚¨ãƒ©ãƒ¼: {self.image_paths[idx]} - {e}")
            return torch.zeros(3, self.img_size, self.img_size), self.labels[idx], self.patient_ids[idx], self.disease_names[idx]

class ProperEvaluationSystem:
    """é©æ­£è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.models = {}
        self.cv_results = defaultdict(list)
        self.final_metrics = {}
        
    def collect_patient_data(self, base_path='/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢'):
        """æ‚£è€…ãƒ™ãƒ¼ã‚¹ã§ã®ãƒ‡ãƒ¼ã‚¿åé›†"""
        print("ğŸ‘¥ æ‚£è€…ãƒ™ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿åé›†ä¸­...")
        
        patient_data = defaultdict(list)
        all_image_paths = []
        all_labels = []
        all_patient_ids = []
        all_disease_names = []
        
        for disease, info in DISEASE_MAPPING.items():
            disease_dir = os.path.join(base_path, disease)
            if not os.path.exists(disease_dir):
                continue
            
            patterns = ['*.jpg', '*.JPG', '*.jpeg', '*.png']
            image_paths = []
            for pattern in patterns:
                image_paths.extend(glob.glob(os.path.join(disease_dir, pattern)))
            
            label = 1 if info['type'] == 'malignant' else 0
            
            # æ‚£è€…IDã‚’ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ç”Ÿæˆï¼ˆã‚ˆã‚Šå³å¯†ã«ï¼‰
            for img_path in image_paths:
                filename = os.path.basename(img_path)
                # ãƒ•ã‚¡ã‚¤ãƒ«åã®æœ€åˆã®éƒ¨åˆ†ã‚’æ‚£è€…IDã¨ã™ã‚‹ï¼ˆä¾‹ï¼šCIMG0001.JPG -> CIMG0001ï¼‰
                patient_id = filename.split('.')[0]
                full_patient_id = f"{disease}_{patient_id}"
                
                all_image_paths.append(img_path)
                all_labels.append(label)
                all_patient_ids.append(full_patient_id)
                all_disease_names.append(disease)
                
                patient_data[full_patient_id].append({
                    'path': img_path,
                    'label': label,
                    'disease': disease
                })
            
            print(f"   {disease}: {len(image_paths)}æš ({'æ‚ªæ€§' if label == 1 else 'è‰¯æ€§'})")
        
        # æ‚£è€…çµ±è¨ˆ
        print(f"\\nğŸ‘¥ æ‚£è€…çµ±è¨ˆ:")
        unique_patients = len(patient_data)
        patient_labels = []
        for patient_id, images in patient_data.items():
            patient_label = images[0]['label']  # æ‚£è€…ã®ç–¾æ‚£ãƒ©ãƒ™ãƒ«
            patient_labels.append(patient_label)
        
        malignant_patients = sum(patient_labels)
        benign_patients = len(patient_labels) - malignant_patients
        
        print(f"   ç·æ‚£è€…æ•°: {unique_patients}äºº")
        print(f"   æ‚ªæ€§æ‚£è€…: {malignant_patients}äºº")
        print(f"   è‰¯æ€§æ‚£è€…: {benign_patients}äºº")
        print(f"   åˆè¨ˆç”»åƒ: {len(all_image_paths)}æš")
        
        return (all_image_paths, all_labels, all_patient_ids, all_disease_names, 
                patient_data, patient_labels)
    
    def train_single_model(self, model_type, train_paths, train_labels, train_patient_ids, train_diseases,
                          val_paths, val_labels, val_patient_ids, val_diseases, fold_idx):
        """å˜ä¸€ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆè©•ä¾¡ç”¨ï¼‰"""
        print(f"\\nğŸš€ {model_type.upper()} è¨“ç·´é–‹å§‹ (Fold {fold_idx + 1})")
        
        # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        model = DualModel(model_type).to(device)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        train_dataset = EvaluationDataset(
            train_paths, train_labels, train_patient_ids, train_diseases, is_training=True
        )
        val_dataset = EvaluationDataset(
            val_paths, val_labels, val_patient_ids, val_diseases, is_training=False
        )
        
        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)
        val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)
        
        # æå¤±é–¢æ•°ã¨ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼
        unique_labels, counts = np.unique(train_labels, return_counts=True)
        class_weights = len(train_labels) / (len(unique_labels) * counts)
        class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)
        
        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor, label_smoothing=0.1)
        optimizer = optim.AdamW(model.parameters(), lr=2e-4, weight_decay=0.01)
        
        # è¨“ç·´ãƒ«ãƒ¼ãƒ—ï¼ˆãƒ•ãƒ«å­¦ç¿’ï¼‰
        best_auc = 0
        best_model_state = None
        epochs = 12  # ãƒ•ãƒ«å­¦ç¿’
        patience = 3  # æ—©æœŸåœæ­¢ã§åŠ¹ç‡åŒ–
        no_improve = 0
        
        for epoch in range(epochs):
            # è¨“ç·´
            model.train()
            train_loss = 0
            for images, labels, _, _ in train_loader:
                images, labels = images.to(device), labels.to(device)
                
                optimizer.zero_grad()
                outputs = model(images)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                
                train_loss += loss.item()
            
            # æ¤œè¨¼
            model.eval()
            val_probs = []
            val_true = []
            
            with torch.no_grad():
                for images, labels, _, _ in val_loader:
                    images = images.to(device)
                    outputs = model(images)
                    probs = torch.softmax(outputs, dim=1)[:, 1]
                    
                    val_probs.extend(probs.cpu().numpy())
                    val_true.extend(labels.numpy())
            
            auc = roc_auc_score(val_true, val_probs)
            
            if auc > best_auc:
                best_auc = auc
                best_model_state = model.state_dict().copy()
                no_improve = 0
            else:
                no_improve += 1
            
            if epoch % 2 == 0:  # é€²æ—è¡¨ç¤ºã‚’æ¸›ã‚‰ã™
                print(f"   Epoch {epoch+1}: Loss {train_loss/len(train_loader):.4f}, AUC {auc:.4f}")
            
            # æ—©æœŸåœæ­¢
            if no_improve >= patience:
                print(f"   æ—©æœŸåœæ­¢ (Epoch {epoch+1})")
                break
        
        # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«å¾©å…ƒ
        model.load_state_dict(best_model_state)
        
        # æœ€çµ‚è©•ä¾¡
        model.eval()
        final_probs = []
        final_true = []
        final_diseases = []
        
        with torch.no_grad():
            for images, labels, _, diseases in val_loader:
                images = images.to(device)
                outputs = model(images)
                probs = torch.softmax(outputs, dim=1)[:, 1]
                
                final_probs.extend(probs.cpu().numpy())
                final_true.extend(labels.numpy())
                final_diseases.extend(diseases)
        
        print(f"âœ… {model_type.upper()} å®Œäº† (AUC: {best_auc:.4f})")
        
        return model, np.array(final_probs), np.array(final_true), final_diseases, best_auc
    
    def cross_validation_evaluation(self, image_paths, labels, patient_ids, disease_names, 
                                   patient_data, patient_labels, n_folds=5):
        """ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è©•ä¾¡"""
        print("\\nğŸ“Š æ‚£è€…IDå±¤åŒ–ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹")
        print("=" * 60)
        
        # æ‚£è€…IDã§ã®å±¤åŒ–K-fold
        unique_patients = list(patient_data.keys())
        skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)
        
        all_cv_results = []
        model_types = ['efficientnet', 'resnet']
        
        for fold_idx, (train_patient_indices, val_patient_indices) in enumerate(skf.split(unique_patients, patient_labels)):
            print(f"\\nğŸ“‚ Fold {fold_idx + 1}/{n_folds}")
            print("-" * 40)
            
            # è¨“ç·´ãƒ»æ¤œè¨¼æ‚£è€…ã‚’åˆ†å‰²
            train_patients = [unique_patients[i] for i in train_patient_indices]
            val_patients = [unique_patients[i] for i in val_patient_indices]
            
            # ç”»åƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
            train_indices = [i for i, pid in enumerate(patient_ids) if pid in train_patients]
            val_indices = [i for i, pid in enumerate(patient_ids) if pid in val_patients]
            
            train_paths = [image_paths[i] for i in train_indices]
            train_labels_fold = [labels[i] for i in train_indices]
            train_patient_ids_fold = [patient_ids[i] for i in train_indices]
            train_diseases_fold = [disease_names[i] for i in train_indices]
            
            val_paths = [image_paths[i] for i in val_indices]
            val_labels_fold = [labels[i] for i in val_indices]
            val_patient_ids_fold = [patient_ids[i] for i in val_indices]
            val_diseases_fold = [disease_names[i] for i in val_indices]
            
            print(f"   è¨“ç·´æ‚£è€…: {len(train_patients)}äºº ({len(train_paths)}æš)")
            print(f"   æ¤œè¨¼æ‚£è€…: {len(val_patients)}äºº ({len(val_paths)}æš)")
            
            fold_results = {}
            fold_ensemble_probs = []
            fold_ensemble_weights = []
            
            # å„ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã§è¨“ç·´ãƒ»è©•ä¾¡
            for model_type in model_types:
                model, val_probs, val_true, val_diseases, auc = self.train_single_model(
                    model_type, train_paths, train_labels_fold, train_patient_ids_fold, train_diseases_fold,
                    val_paths, val_labels_fold, val_patient_ids_fold, val_diseases_fold, fold_idx
                )
                
                fold_results[model_type] = {
                    'auc': auc,
                    'probs': val_probs,
                    'true': val_true,
                    'diseases': val_diseases
                }
                
                fold_ensemble_probs.append(val_probs)
                fold_ensemble_weights.append(auc)
                
                self.cv_results[model_type].append(auc)
            
            # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è©•ä¾¡
            total_weight = sum(fold_ensemble_weights)
            ensemble_weights = [w / total_weight for w in fold_ensemble_weights]
            
            ensemble_probs = np.zeros_like(fold_ensemble_probs[0])
            for i, (probs, weight) in enumerate(zip(fold_ensemble_probs, ensemble_weights)):
                ensemble_probs += weight * probs
            
            ensemble_auc = roc_auc_score(val_true, ensemble_probs)
            self.cv_results['ensemble'].append(ensemble_auc)
            
            # Foldè©³ç´°è©•ä¾¡
            fold_metrics = self.calculate_detailed_metrics(
                val_true, ensemble_probs, val_diseases_fold, fold_idx
            )
            
            all_cv_results.append({
                'fold': fold_idx + 1,
                'individual_results': fold_results,
                'ensemble_auc': ensemble_auc,
                'ensemble_weights': dict(zip(model_types, ensemble_weights)),
                'detailed_metrics': fold_metrics,
                'validation_patients': val_patients,
                'validation_diseases': val_diseases_fold
            })
        
        return all_cv_results
    
    def calculate_detailed_metrics(self, y_true, y_probs, diseases, fold_idx):
        """è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—"""
        # è¤‡æ•°ã®é–¾å€¤ã§è©•ä¾¡
        thresholds = [0.3, 0.5, 0.7]
        metrics = {}
        
        for threshold in thresholds:
            y_pred = (y_probs >= threshold).astype(int)
            
            # å…¨ä½“ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
            
            sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0
            specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            recall = sensitivity
            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
            accuracy = (tp + tn) / (tp + tn + fp + fn)
            
            metrics[f'threshold_{threshold}'] = {
                'confusion_matrix': {'TP': int(tp), 'TN': int(tn), 'FP': int(fp), 'FN': int(fn)},
                'sensitivity': float(sensitivity),
                'specificity': float(specificity),
                'precision': float(precision),
                'recall': float(recall),
                'f1_score': float(f1),
                'accuracy': float(accuracy)
            }
        
        # ç–¾æ‚£åˆ¥è©•ä¾¡
        disease_metrics = {}
        unique_diseases = list(set(diseases))
        
        for disease in unique_diseases:
            disease_indices = [i for i, d in enumerate(diseases) if d == disease]
            if len(disease_indices) == 0:
                continue
                
            disease_true = [y_true[i] for i in disease_indices]
            disease_probs = [y_probs[i] for i in disease_indices]
            
            if len(set(disease_true)) > 1:  # ä¸¡ã‚¯ãƒ©ã‚¹ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿AUCè¨ˆç®—
                disease_auc = roc_auc_score(disease_true, disease_probs)
            else:
                disease_auc = None
            
            disease_metrics[disease] = {
                'count': len(disease_indices),
                'auc': disease_auc,
                'mean_prob': float(np.mean(disease_probs)),
                'std_prob': float(np.std(disease_probs))
            }
        
        return {
            'overall_metrics': metrics,
            'disease_specific': disease_metrics,
            'auc': float(roc_auc_score(y_true, y_probs))
        }
    
    def generate_final_report(self, cv_results):
        """æœ€çµ‚è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("\\n" + "=" * 80)
        print("ğŸ“‹ çœŸã®æ€§èƒ½è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯å›é¿ï¼‰")
        print("=" * 80)
        
        # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚µãƒãƒªãƒ¼
        print("\\nğŸ“Š ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœ:")
        print("-" * 50)
        
        for model_type, aucs in self.cv_results.items():
            mean_auc = np.mean(aucs)
            std_auc = np.std(aucs)
            print(f"   {model_type.upper()}: {mean_auc:.4f} Â± {std_auc:.4f}")
        
        # è©³ç´°çµ±è¨ˆ
        ensemble_aucs = self.cv_results['ensemble']
        mean_ensemble_auc = np.mean(ensemble_aucs)
        std_ensemble_auc = np.std(ensemble_aucs)
        
        print(f"\\nğŸ¯ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æœ€çµ‚æ€§èƒ½:")
        print(f"   å¹³å‡AUC: {mean_ensemble_auc:.4f} Â± {std_ensemble_auc:.4f}")
        print(f"   æœ€é«˜AUC: {np.max(ensemble_aucs):.4f}")
        print(f"   æœ€ä½AUC: {np.min(ensemble_aucs):.4f}")
        
        # é–¾å€¤åˆ¥æ€§èƒ½ï¼ˆå…¨Foldå¹³å‡ï¼‰
        print(f"\\nğŸ“ˆ é–¾å€¤åˆ¥æ€§èƒ½ï¼ˆ5-Foldå¹³å‡ï¼‰:")
        print("-" * 50)
        
        threshold_results = {0.3: [], 0.5: [], 0.7: []}
        
        for fold_result in cv_results:
            metrics = fold_result['detailed_metrics']['overall_metrics']
            for threshold in [0.3, 0.5, 0.7]:
                threshold_results[threshold].append(metrics[f'threshold_{threshold}'])
        
        for threshold, results in threshold_results.items():
            sens_mean = np.mean([r['sensitivity'] for r in results])
            spec_mean = np.mean([r['specificity'] for r in results])
            acc_mean = np.mean([r['accuracy'] for r in results])
            
            print(f"   é–¾å€¤ {threshold}: æ„Ÿåº¦ {sens_mean:.3f}, ç‰¹ç•°åº¦ {spec_mean:.3f}, ç²¾åº¦ {acc_mean:.3f}")
        
        # ç–¾æ‚£åˆ¥æ€§èƒ½
        print(f"\\nğŸ”¬ ç–¾æ‚£åˆ¥æ€§èƒ½:")
        print("-" * 50)
        
        all_diseases = set()
        for fold_result in cv_results:
            all_diseases.update(fold_result['detailed_metrics']['disease_specific'].keys())
        
        for disease in sorted(all_diseases):
            disease_aucs = []
            disease_counts = []
            
            for fold_result in cv_results:
                disease_data = fold_result['detailed_metrics']['disease_specific'].get(disease, {})
                if disease_data.get('auc') is not None:
                    disease_aucs.append(disease_data['auc'])
                if 'count' in disease_data:
                    disease_counts.append(disease_data['count'])
            
            if disease_aucs:
                mean_auc = np.mean(disease_aucs)
                total_samples = np.sum(disease_counts)
                disease_type = DISEASE_MAPPING.get(disease, {}).get('type', 'unknown')
                
                print(f"   {disease} ({disease_type}): AUC {mean_auc:.3f}, ç·ã‚µãƒ³ãƒ—ãƒ« {total_samples}æš")
        
        # ä¿¡é ¼åŒºé–“
        confidence_level = 0.95
        z_score = 1.96  # 95%ä¿¡é ¼åŒºé–“
        n_folds = len(ensemble_aucs)
        
        margin_of_error = z_score * (std_ensemble_auc / np.sqrt(n_folds))
        ci_lower = mean_ensemble_auc - margin_of_error
        ci_upper = mean_ensemble_auc + margin_of_error
        
        print(f"\\nğŸ“ çµ±è¨ˆçš„ä¿¡é ¼æ€§:")
        print(f"   95%ä¿¡é ¼åŒºé–“: [{ci_lower:.4f}, {ci_upper:.4f}]")
        print(f"   æ¨™æº–èª¤å·®: {std_ensemble_auc / np.sqrt(n_folds):.4f}")
        
        # SKç‰¹åŒ–è©•ä¾¡
        print(f"\\nğŸ¯ SKèª¤åˆ†é¡æ”¹å–„åŠ¹æœ:")
        print("-" * 50)
        
        sk_results = []
        for fold_result in cv_results:
            sk_data = fold_result['detailed_metrics']['disease_specific'].get('SK', {})
            if 'mean_prob' in sk_data:
                sk_results.append(sk_data['mean_prob'])
        
        if sk_results:
            sk_mean_prob = np.mean(sk_results)
            sk_std_prob = np.std(sk_results)
            
            print(f"   SKå¹³å‡æ‚ªæ€§ç¢ºç‡: {sk_mean_prob:.1%} Â± {sk_std_prob:.1%}")
            print(f"   å¾“æ¥ã‚·ã‚¹ãƒ†ãƒ : 99.8% â†’ æ”¹å–„æ¸ˆã¿: {sk_mean_prob:.1%}")
            print(f"   æ”¹å–„åŠ¹æœ: {99.8 - sk_mean_prob*100:.1f}ãƒã‚¤ãƒ³ãƒˆæ¸›å°‘")
            
            if sk_mean_prob < 0.5:
                print("   âœ… SKèª¤åˆ†é¡å•é¡ŒãŒè§£æ±ºã•ã‚Œã¦ã„ã¾ã™")
            else:
                print("   âš ï¸ SKèª¤åˆ†é¡ãŒã¾ã æ®‹å­˜ã—ã¦ã„ã¾ã™")
        
        # æœ€çµ‚çµè«–
        print(f"\\n" + "=" * 80)
        print("ğŸ† æœ€çµ‚çµè«–")
        print("=" * 80)
        
        if mean_ensemble_auc >= 0.95:
            performance_grade = "å„ªç§€"
            clinical_readiness = "è‡¨åºŠå¿œç”¨å¯èƒ½ãƒ¬ãƒ™ãƒ«"
        elif mean_ensemble_auc >= 0.90:
            performance_grade = "è‰¯å¥½"
            clinical_readiness = "æ›´ãªã‚‹æ”¹å–„æ¨å¥¨"
        else:
            performance_grade = "è¦æ”¹å–„"
            clinical_readiness = "è¿½åŠ é–‹ç™ºå¿…è¦"
        
        print(f"ğŸ“Š æ€§èƒ½è©•ä¾¡: {performance_grade}")
        print(f"ğŸ¥ è‡¨åºŠå¿œç”¨: {clinical_readiness}")
        print(f"ğŸ“ˆ ä¿¡é ¼æ€§: ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯å›é¿ã«ã‚ˆã‚‹çœŸã®æ€§èƒ½è©•ä¾¡æ¸ˆã¿")
        
        # çµæœä¿å­˜
        final_results = {
            'cross_validation_summary': {
                'n_folds': len(ensemble_aucs),
                'mean_auc': float(mean_ensemble_auc),
                'std_auc': float(std_ensemble_auc),
                'confidence_interval_95': [float(ci_lower), float(ci_upper)],
                'individual_fold_aucs': [float(auc) for auc in ensemble_aucs]
            },
            'model_performance': {model_type: {'mean_auc': float(np.mean(aucs)), 'std_auc': float(np.std(aucs))} 
                                for model_type, aucs in self.cv_results.items()},
            'detailed_cv_results': cv_results,
            'performance_grade': performance_grade,
            'clinical_readiness': clinical_readiness
        }
        
        with open('/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢/proper_evaluation_results.json', 'w', encoding='utf-8') as f:
            # numpyå‹ã‚’JSONå¯¾å¿œå‹ã«å¤‰æ›
            def convert_numpy(obj):
                if isinstance(obj, np.integer):
                    return int(obj)
                elif isinstance(obj, np.floating):
                    return float(obj)
                elif isinstance(obj, np.ndarray):
                    return obj.tolist()
                return obj
            
            json.dump(final_results, f, indent=2, ensure_ascii=False, default=convert_numpy)
        
        print(f"\\nğŸ’¾ è©³ç´°çµæœã‚’ä¿å­˜: proper_evaluation_results.json")
        
        return final_results

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸ”¬ é©æ­£è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ")
    print("   ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯å›é¿ã«ã‚ˆã‚‹çœŸã®æ€§èƒ½æ¸¬å®š")
    print("=" * 80)
    
    evaluator = ProperEvaluationSystem()
    
    # æ‚£è€…ãƒ™ãƒ¼ã‚¹ã§ã®ãƒ‡ãƒ¼ã‚¿åé›†
    (image_paths, labels, patient_ids, disease_names, 
     patient_data, patient_labels) = evaluator.collect_patient_data()
    
    if len(image_paths) == 0:
        print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è©•ä¾¡
    cv_results = evaluator.cross_validation_evaluation(
        image_paths, labels, patient_ids, disease_names,
        patient_data, patient_labels, n_folds=5
    )
    
    # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    final_results = evaluator.generate_final_report(cv_results)
    
    print(f"\\nğŸ‰ é©æ­£è©•ä¾¡å®Œäº†ï¼")
    print(f"   çœŸã®æ€§èƒ½ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯å›é¿ï¼‰ãŒç¢ºèªã•ã‚Œã¾ã—ãŸ")

if __name__ == "__main__":
    main()