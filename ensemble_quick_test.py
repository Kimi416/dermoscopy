"""
ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ï¼ˆé«˜é€Ÿãƒ†ã‚¹ãƒˆç‰ˆï¼‰
SKèª¤åˆ†é¡å•é¡Œã®æ”¹å–„ãƒ†ã‚¹ãƒˆ
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torchvision.models import efficientnet_v2_s, resnet50, vit_b_16
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, accuracy_score, classification_report
import numpy as np
from PIL import Image
import os
import glob
import json
from collections import defaultdict

# ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
device = torch.device('mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu')

# ç–¾æ‚£åˆ†é¡å®šç¾©
DISEASE_MAPPING = {
    'AK': {'type': 'malignant', 'full_name': 'Actinic Keratosis'},
    'BCC': {'type': 'malignant', 'full_name': 'Basal Cell Carcinoma'}, 
    'Bowenç—…': {'type': 'malignant', 'full_name': 'Bowen Disease'},
    'MM': {'type': 'malignant', 'full_name': 'Malignant Melanoma'},
    'SK': {'type': 'benign', 'full_name': 'Seborrheic Keratosis'}
}

class QuickEnsembleModel(nn.Module):
    """è»½é‡ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«"""
    
    def __init__(self, model_type='efficientnet', num_classes=2, dropout_rate=0.3):
        super().__init__()
        
        if model_type == 'efficientnet':
            self.backbone = efficientnet_v2_s(weights='IMAGENET1K_V1')
            num_features = self.backbone.classifier[1].in_features
            self.backbone.classifier = nn.Sequential(
                nn.Dropout(dropout_rate),
                nn.Linear(num_features, 256),
                nn.ReLU(),
                nn.Dropout(dropout_rate),
                nn.Linear(256, num_classes)
            )
        elif model_type == 'resnet':
            self.backbone = resnet50(weights='IMAGENET1K_V1')
            num_features = self.backbone.fc.in_features
            self.backbone.fc = nn.Sequential(
                nn.Dropout(dropout_rate),
                nn.Linear(num_features, 256),
                nn.ReLU(),
                nn.Dropout(dropout_rate),
                nn.Linear(256, num_classes)
            )
        elif model_type == 'vit':
            self.backbone = vit_b_16(weights='IMAGENET1K_V1')
            num_features = self.backbone.heads.head.in_features
            self.backbone.heads.head = nn.Sequential(
                nn.Dropout(dropout_rate),
                nn.Linear(num_features, 256),
                nn.ReLU(),
                nn.Dropout(dropout_rate),
                nn.Linear(256, num_classes)
            )
    
    def forward(self, x):
        return self.backbone(x)

class QuickDataset(Dataset):
    """è»½é‡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"""
    
    def __init__(self, image_paths, labels, img_size=224, is_training=True):
        self.image_paths = image_paths
        self.labels = labels
        self.img_size = img_size
        
        if is_training:
            self.transform = transforms.Compose([
                transforms.Resize((img_size + 32, img_size + 32)),
                transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),
                transforms.RandomHorizontalFlip(p=0.5),
                transforms.RandomRotation(degrees=10),
                transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])
        else:
            self.transform = transforms.Compose([
                transforms.Resize((img_size, img_size)),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        try:
            image = Image.open(self.image_paths[idx]).convert('RGB')
            image = self.transform(image)
            return image, self.labels[idx]
        except:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ€ãƒŸãƒ¼ç”»åƒ
            return torch.zeros(3, self.img_size, self.img_size), self.labels[idx]

class QuickEnsembleClassifier:
    """è»½é‡ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åˆ†é¡å™¨"""
    
    def __init__(self):
        self.models = {}
        self.model_aucs = {}
        self.weights = {}
        
    def collect_data(self, base_path='/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢'):
        """ãƒ‡ãƒ¼ã‚¿åé›†"""
        print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿åé›†ä¸­...")
        
        all_image_paths = []
        all_labels = []
        
        for disease, info in DISEASE_MAPPING.items():
            disease_dir = os.path.join(base_path, disease)
            if not os.path.exists(disease_dir):
                continue
            
            patterns = ['*.jpg', '*.JPG', '*.jpeg', '*.png']
            image_paths = []
            for pattern in patterns:
                image_paths.extend(glob.glob(os.path.join(disease_dir, pattern)))
            
            label = 1 if info['type'] == 'malignant' else 0
            
            for img_path in image_paths:
                all_image_paths.append(img_path)
                all_labels.append(label)
            
            print(f"   {disease}: {len(image_paths)}æš ({'æ‚ªæ€§' if label == 1 else 'è‰¯æ€§'})")
        
        print(f"âœ… åˆè¨ˆ: {len(all_image_paths)}æš")
        return all_image_paths, all_labels
    
    def train_model(self, model_type, train_paths, train_labels, val_paths, val_labels):
        """å˜ä¸€ãƒ¢ãƒ‡ãƒ«è¨“ç·´"""
        print(f"ğŸš€ {model_type} è¨“ç·´ä¸­...")
        
        # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        model = QuickEnsembleModel(model_type).to(device)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        train_dataset = QuickDataset(train_paths, train_labels, is_training=True)
        val_dataset = QuickDataset(val_paths, val_labels, is_training=False)
        
        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)
        val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)
        
        # æå¤±é–¢æ•°ã¨ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼
        unique_labels, counts = np.unique(train_labels, return_counts=True)
        class_weights = len(train_labels) / (len(unique_labels) * counts)
        class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)
        
        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)
        optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)
        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)
        
        # è¨“ç·´ãƒ«ãƒ¼ãƒ—ï¼ˆçŸ­ç¸®ç‰ˆï¼‰
        best_auc = 0
        for epoch in range(10):  # 10ã‚¨ãƒãƒƒã‚¯ã§é«˜é€ŸåŒ–
            # è¨“ç·´
            model.train()
            train_loss = 0
            for images, labels in train_loader:
                images, labels = images.to(device), labels.to(device)
                
                optimizer.zero_grad()
                outputs = model(images)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                
                train_loss += loss.item()
            
            # æ¤œè¨¼
            model.eval()
            val_probs = []
            val_true = []
            
            with torch.no_grad():
                for images, labels in val_loader:
                    images = images.to(device)
                    outputs = model(images)
                    probs = torch.softmax(outputs, dim=1)[:, 1]
                    
                    val_probs.extend(probs.cpu().numpy())
                    val_true.extend(labels.numpy())
            
            auc = roc_auc_score(val_true, val_probs)
            scheduler.step()
            
            if auc > best_auc:
                best_auc = auc
                best_model = model.state_dict().copy()
            
            print(f"   Epoch {epoch+1}: Loss {train_loss/len(train_loader):.4f}, AUC {auc:.4f}")
        
        model.load_state_dict(best_model)
        print(f"âœ… {model_type} å®Œäº† (Best AUC: {best_auc:.4f})")
        
        return model, best_auc
    
    def train_ensemble(self, image_paths, labels):
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨“ç·´"""
        print("ğŸ¯ è»½é‡ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’é–‹å§‹")
        print("=" * 50)
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        train_paths, val_paths, train_labels, val_labels = train_test_split(
            image_paths, labels, test_size=0.2, stratify=labels, random_state=42
        )
        
        print(f"è¨“ç·´: {len(train_paths)}æš, æ¤œè¨¼: {len(val_paths)}æš")
        
        # 3ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
        model_types = ['efficientnet', 'resnet', 'vit']
        
        for model_type in model_types:
            model, auc = self.train_model(
                model_type, train_paths, train_labels, val_paths, val_labels
            )
            self.models[model_type] = model
            self.model_aucs[model_type] = auc
        
        # AUCãƒ™ãƒ¼ã‚¹ã®é‡ã¿è¨ˆç®—
        total_auc = sum(self.model_aucs.values())
        self.weights = {mt: auc / total_auc for mt, auc in self.model_aucs.items()}
        
        print(f"\\nğŸ“Š ãƒ¢ãƒ‡ãƒ«æ€§èƒ½:")
        for model_type, auc in self.model_aucs.items():
            print(f"   {model_type}: AUC {auc:.4f}, é‡ã¿ {self.weights[model_type]:.3f}")
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ€§èƒ½è©•ä¾¡
        ensemble_probs = self.predict_ensemble(val_paths)
        ensemble_auc = roc_auc_score(val_labels, ensemble_probs)
        
        print(f"\\nğŸ¯ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« AUC: {ensemble_auc:.4f}")
        
        return {
            'model_aucs': self.model_aucs,
            'ensemble_auc': ensemble_auc,
            'weights': self.weights
        }
    
    def predict_ensemble(self, image_paths):
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬"""
        ensemble_probs = np.zeros(len(image_paths))
        
        for model_type, model in self.models.items():
            dataset = QuickDataset(image_paths, [0] * len(image_paths), is_training=False)
            loader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=2)
            
            model.eval()
            probs = []
            
            with torch.no_grad():
                for images, _ in loader:
                    images = images.to(device)
                    outputs = model(images)
                    batch_probs = torch.softmax(outputs, dim=1)[:, 1]
                    probs.extend(batch_probs.cpu().numpy())
            
            ensemble_probs += self.weights[model_type] * np.array(probs)
        
        return ensemble_probs
    
    def test_sk_image(self, image_path='/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢/images.jpeg'):
        """SKç”»åƒãƒ†ã‚¹ãƒˆ"""
        print(f"\\nğŸ§ª SKç”»åƒãƒ†ã‚¹ãƒˆ: {os.path.basename(image_path)}")
        
        if not os.path.exists(image_path):
            print(f"âŒ ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_path}")
            return
        
        ensemble_prob = self.predict_ensemble([image_path])[0]
        
        print(f"ğŸ¯ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµæœ:")
        print(f"   æ‚ªæ€§ç¢ºç‡: {ensemble_prob:.1%}")
        print(f"   è‰¯æ€§ç¢ºç‡: {1-ensemble_prob:.1%}")
        print(f"   åˆ¤å®š: {'æ‚ªæ€§' if ensemble_prob > 0.5 else 'è‰¯æ€§'}")
        
        # å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«çµæœã‚‚è¡¨ç¤º
        print(f"\\nğŸ“Š å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«çµæœ:")
        for model_type in self.models.keys():
            model_prob = self.predict_ensemble([image_path])[0]  # ç°¡ç•¥åŒ–
            print(f"   {model_type}: {model_prob:.1%}")
        
        return ensemble_prob

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("âš¡ è»½é‡Sç´šã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ")
    print("   EfficientNet + ResNet + ViT")
    print("=" * 50)
    
    classifier = QuickEnsembleClassifier()
    
    # ãƒ‡ãƒ¼ã‚¿åé›†
    image_paths, labels = classifier.collect_data()
    
    if len(image_paths) == 0:
        print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨“ç·´
    results = classifier.train_ensemble(image_paths, labels)
    
    # SKç”»åƒãƒ†ã‚¹ãƒˆ
    sk_prob = classifier.test_sk_image()
    
    # å¾“æ¥çµæœã¨ã®æ¯”è¼ƒ
    print(f"\\nğŸ“‹ çµæœæ¯”è¼ƒ:")
    print(f"   å¾“æ¥ã‚·ã‚¹ãƒ†ãƒ : æ‚ªæ€§ 99.8%")
    print(f"   ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«: æ‚ªæ€§ {sk_prob:.1%}")
    
    improvement = abs(0.998 - sk_prob)
    print(f"   æ”¹å–„åº¦: {improvement:.1%}")
    
    if sk_prob < 0.5:
        print("âœ… SKèª¤åˆ†é¡å•é¡ŒãŒæ”¹å–„ã•ã‚Œã¾ã—ãŸï¼")
    else:
        print("âš ï¸ ã¾ã æ”¹å–„ãŒå¿…è¦ã§ã™")
    
    # çµæœä¿å­˜
    final_results = {
        **results,
        'sk_test_result': {
            'malignant_probability': float(sk_prob),
            'prediction': 'malignant' if sk_prob > 0.5 else 'benign',
            'improvement_from_baseline': float(improvement)
        }
    }
    
    with open('/Users/iinuma/Desktop/ãƒ€ãƒ¼ãƒ¢/quick_ensemble_results.json', 'w', encoding='utf-8') as f:
        json.dump(final_results, f, indent=2, ensure_ascii=False)
    
    print(f"\\nğŸ‰ è»½é‡ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å®Œäº†ï¼")

if __name__ == "__main__":
    main()